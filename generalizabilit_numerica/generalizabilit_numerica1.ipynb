{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "137c8771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] Main experiment directory: ./experiment_hundreds_CI_20250909_164549\n",
      "[INIT] Using device: cuda:0\n",
      "\n",
      "===== Loading model: /root/autodl-tmp/Qwen2.5-Math-7B =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:820: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea8c05fecbc4a9e95ee859a43bbd617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Model loaded.\n",
      "[INFO] Layers to probe (first 5 shown): [0, 1, 2, 3, 4]... total 29 layers (including embedding layer 0).\n",
      "\n",
      "--- Repetition 1/5 | Seed = 42 ---\n",
      "[OK] Total addition train+test samples: 5000\n",
      "[OK] Multiplication test samples: 500\n",
      "[OK] Subtraction test samples: 500\n",
      "[ACT] Extracting activations for ADDITION...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52afd5704ef4623954c7c06a00239c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ADD S42 Extracting activations:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed4620b5fb446ce965263caff3781c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MULT S42 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5630870e2caa4a5f901753953dbcb889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SUB S42 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROBE] Start layer-wise probing (0..28)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9049510e1b4742801359f9884b80cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Probing Layers S42:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Layer-wise probing finished for Seed 42.\n",
      "\n",
      "--- Repetition 2/5 | Seed = 43 ---\n",
      "[OK] Total addition train+test samples: 5000\n",
      "[OK] Multiplication test samples: 500\n",
      "[OK] Subtraction test samples: 500\n",
      "[ACT] Extracting activations for ADDITION...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50c2ca6885b41239b6afcba521b5ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ADD S43 Extracting activations:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4786b144ddd7428cb5ef9aac63e2bacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MULT S43 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c68228b2ec47f296272eb7b4be6264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SUB S43 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROBE] Start layer-wise probing (0..28)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c554df2f184777bfe372d58d51cced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Probing Layers S43:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Layer-wise probing finished for Seed 43.\n",
      "\n",
      "--- Repetition 3/5 | Seed = 44 ---\n",
      "[OK] Total addition train+test samples: 5000\n",
      "[OK] Multiplication test samples: 500\n",
      "[OK] Subtraction test samples: 500\n",
      "[ACT] Extracting activations for ADDITION...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da3f458ae684a129a6fe352b8a35c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ADD S44 Extracting activations:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d4676a1a744b1d8c15d173d1b1d0a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MULT S44 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc2de0ca83044e98850afdf5c565cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SUB S44 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROBE] Start layer-wise probing (0..28)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943f8569632d41d9a9ffcde554e1f0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Probing Layers S44:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Layer-wise probing finished for Seed 44.\n",
      "\n",
      "--- Repetition 4/5 | Seed = 45 ---\n",
      "[OK] Total addition train+test samples: 5000\n",
      "[OK] Multiplication test samples: 500\n",
      "[OK] Subtraction test samples: 500\n",
      "[ACT] Extracting activations for ADDITION...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661b89add1aa4587a68a1d440611e3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ADD S45 Extracting activations:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941f21dbac7d44c0bdc4fec6429f6510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MULT S45 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8231271ef329406dad99617f88d2cfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SUB S45 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROBE] Start layer-wise probing (0..28)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28025abff9434cf885df40aa25e79713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Probing Layers S45:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Layer-wise probing finished for Seed 45.\n",
      "\n",
      "--- Repetition 5/5 | Seed = 46 ---\n",
      "[OK] Total addition train+test samples: 5000\n",
      "[OK] Multiplication test samples: 500\n",
      "[OK] Subtraction test samples: 500\n",
      "[ACT] Extracting activations for ADDITION...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41eb088839ac45c2ac48349aa8d9b4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ADD S46 Extracting activations:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57909f2d6d645b6a52842c8c8587f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MULT S46 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772a864f55e1423c86360b668fa15157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SUB S46 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROBE] Start layer-wise probing (0..28)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46872f8d3670476eb7abd9d162765edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Probing Layers S46:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Layer-wise probing finished for Seed 46.\n",
      "\n",
      "[AGG] Computing final statistics...\n",
      "ADDITION Test Accuracy: Mean=0.1277, 95.0% CI=(0.1223, 0.1331), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.0664, 95.0% CI=(0.0152, 0.1176), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0760, 95.0% CI=(0.0611, 0.0909), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1301, 95.0% CI=(0.1185, 0.1416), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.0832, 95.0% CI=(0.0428, 0.1236), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0764, 95.0% CI=(0.0074, 0.1454), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1389, 95.0% CI=(0.1240, 0.1537), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.0700, 95.0% CI=(0.0466, 0.0934), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1324, 95.0% CI=(0.0185, 0.2463), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1437, 95.0% CI=(0.1303, 0.1571), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1212, 95.0% CI=(0.0600, 0.1824), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0908, 95.0% CI=(0.0357, 0.1459), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1422, 95.0% CI=(0.1204, 0.1641), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1048, 95.0% CI=(0.0399, 0.1697), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1024, 95.0% CI=(0.0042, 0.2006), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1642, 95.0% CI=(0.1424, 0.1859), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1556, 95.0% CI=(0.1073, 0.2039), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1320, 95.0% CI=(0.0604, 0.2036), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1454, 95.0% CI=(0.1117, 0.1792), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1628, 95.0% CI=(0.1418, 0.1838), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1028, 95.0% CI=(0.0038, 0.2018), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1760, 95.0% CI=(0.1613, 0.1907), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1940, 95.0% CI=(0.1658, 0.2222), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0888, 95.0% CI=(0.0537, 0.1239), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1872, 95.0% CI=(0.1573, 0.2171), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1760, 95.0% CI=(0.1380, 0.2140), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0680, 95.0% CI=(0.0256, 0.1104), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1955, 95.0% CI=(0.1632, 0.2279), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1728, 95.0% CI=(0.1111, 0.2345), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0752, 95.0% CI=(0.0228, 0.1276), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2246, 95.0% CI=(0.2033, 0.2460), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1608, 95.0% CI=(0.1511, 0.1705), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0944, 95.0% CI=(0.0402, 0.1486), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2038, 95.0% CI=(0.1898, 0.2178), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1424, 95.0% CI=(0.1074, 0.1774), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0840, 95.0% CI=(0.0650, 0.1030), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2259, 95.0% CI=(0.1962, 0.2556), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1440, 95.0% CI=(0.0892, 0.1988), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0712, 95.0% CI=(0.0325, 0.1099), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2162, 95.0% CI=(0.1968, 0.2355), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1608, 95.0% CI=(0.1249, 0.1967), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0536, 95.0% CI=(0.0301, 0.0771), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2258, 95.0% CI=(0.2077, 0.2438), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1784, 95.0% CI=(0.1568, 0.2000), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0504, 95.0% CI=(0.0294, 0.0714), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2286, 95.0% CI=(0.2093, 0.2480), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1984, 95.0% CI=(0.1758, 0.2210), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0704, 95.0% CI=(0.0053, 0.1355), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2309, 95.0% CI=(0.2088, 0.2529), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1608, 95.0% CI=(0.1319, 0.1897), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0712, 95.0% CI=(0.0491, 0.0933), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2402, 95.0% CI=(0.2152, 0.2651), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1844, 95.0% CI=(0.1383, 0.2305), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0508, 95.0% CI=(0.0281, 0.0735), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2632, 95.0% CI=(0.2289, 0.2975), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1844, 95.0% CI=(0.1554, 0.2134), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0780, 95.0% CI=(0.0257, 0.1303), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.3019, 95.0% CI=(0.2910, 0.3128), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1820, 95.0% CI=(0.1429, 0.2211), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0812, 95.0% CI=(0.0385, 0.1239), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2954, 95.0% CI=(0.2734, 0.3173), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1568, 95.0% CI=(0.1141, 0.1995), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0692, 95.0% CI=(0.0441, 0.0943), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2925, 95.0% CI=(0.2731, 0.3119), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1288, 95.0% CI=(0.0616, 0.1960), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1300, 95.0% CI=(0.0597, 0.2003), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.3733, 95.0% CI=(0.3543, 0.3922), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.0888, 95.0% CI=(0.0517, 0.1259), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0852, 95.0% CI=(0.0357, 0.1347), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.4768, 95.0% CI=(0.4500, 0.5036), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1200, 95.0% CI=(0.1137, 0.1263), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1152, 95.0% CI=(0.0574, 0.1730), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.7389, 95.0% CI=(0.7171, 0.7607), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.2368, 95.0% CI=(0.2174, 0.2562), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.4388, 95.0% CI=(0.3878, 0.4898), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.8402, 95.0% CI=(0.8229, 0.8575), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.4596, 95.0% CI=(0.3984, 0.5208), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.6032, 95.0% CI=(0.5894, 0.6170), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.8685, 95.0% CI=(0.8594, 0.8776), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.5356, 95.0% CI=(0.5183, 0.5529), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.6556, 95.0% CI=(0.6032, 0.7080), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.8632, 95.0% CI=(0.8445, 0.8819), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.5512, 95.0% CI=(0.5292, 0.5732), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.6928, 95.0% CI=(0.6400, 0.7456), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.8773, 95.0% CI=(0.8669, 0.8876), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.5228, 95.0% CI=(0.4709, 0.5747), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.6792, 95.0% CI=(0.6559, 0.7025), N_valid_runs=5\n",
      "[SAVE] Plot saved: ./experiment_hundreds_CI_20250909_164549/Qwen2.5-Math-7B/Qwen2.5-Math-7B_mean_probe_accuracy_CI_20250909_164549.pdf\n",
      "[SAVE] Plot saved: ./experiment_hundreds_CI_20250909_164549/Qwen2.5-Math-7B/Qwen2.5-Math-7B_mean_probe_accuracy_CI_20250909_164549.png\n",
      "[LOG] Aggregated log: ./experiment_hundreds_CI_20250909_164549/Qwen2.5-Math-7B/AGGREGATED_probe_log_Qwen2.5-Math-7B_20250909_164549.txt\n",
      "[OK ] Model /root/autodl-tmp/Qwen2.5-Math-7B finished; results at: ./experiment_hundreds_CI_20250909_164549/Qwen2.5-Math-7B\n",
      "\n",
      "===== Loading model: /root/autodl-tmp/Qwen2.5-7B-Instruct =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:820: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7451c15c7ac4f2eaca180fcd89b556d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Model loaded.\n",
      "[INFO] Layers to probe (first 5 shown): [0, 1, 2, 3, 4]... total 29 layers (including embedding layer 0).\n",
      "\n",
      "--- Repetition 1/5 | Seed = 42 ---\n",
      "[OK] Total addition train+test samples: 5000\n",
      "[OK] Multiplication test samples: 500\n",
      "[OK] Subtraction test samples: 500\n",
      "[ACT] Extracting activations for ADDITION...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963689915d1f47d8a30624b00f8333bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ADD S42 Extracting activations:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4c36e71634490abff4064ac8deb9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MULT S42 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab088f81c3a24faa8dcb3d9b5ca316c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SUB S42 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROBE] Start layer-wise probing (0..28)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d16997ad264af4b839734793b90fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Probing Layers S42:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Layer-wise probing finished for Seed 42.\n",
      "\n",
      "--- Repetition 2/5 | Seed = 43 ---\n",
      "[OK] Total addition train+test samples: 5000\n",
      "[OK] Multiplication test samples: 500\n",
      "[OK] Subtraction test samples: 500\n",
      "[ACT] Extracting activations for ADDITION...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a7f0f6e3aa491bb48a68fe0b07f287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ADD S43 Extracting activations:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a8400fe31c4177b90287adcf522744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MULT S43 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270454650f8c493fb49b4ceb9cd5640b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SUB S43 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROBE] Start layer-wise probing (0..28)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef669f36caf44bf8ece17e4d608ffcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Probing Layers S43:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Layer-wise probing finished for Seed 43.\n",
      "\n",
      "--- Repetition 3/5 | Seed = 44 ---\n",
      "[OK] Total addition train+test samples: 5000\n",
      "[OK] Multiplication test samples: 500\n",
      "[OK] Subtraction test samples: 500\n",
      "[ACT] Extracting activations for ADDITION...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3816c0b4d84ec18c295feb53abffa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ADD S44 Extracting activations:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62fb46a85afe4afa8b385800b950c6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MULT S44 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d25f513097416abe3cc1246da2d2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SUB S44 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROBE] Start layer-wise probing (0..28)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5162b3ce84bd40d7b8cb31dbcfb4f5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Probing Layers S44:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Layer-wise probing finished for Seed 44.\n",
      "\n",
      "--- Repetition 4/5 | Seed = 45 ---\n",
      "[OK] Total addition train+test samples: 5000\n",
      "[OK] Multiplication test samples: 500\n",
      "[OK] Subtraction test samples: 500\n",
      "[ACT] Extracting activations for ADDITION...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af766fadd7e0480bb749dd391f1679c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ADD S45 Extracting activations:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772db2dd8e9b43e3975e7ec2e1094297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MULT S45 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c585c0ceb184ef7b31175df7747d26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SUB S45 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROBE] Start layer-wise probing (0..28)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c508c10031c4c20a346734cd347cdcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Probing Layers S45:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Layer-wise probing finished for Seed 45.\n",
      "\n",
      "--- Repetition 5/5 | Seed = 46 ---\n",
      "[OK] Total addition train+test samples: 5000\n",
      "[OK] Multiplication test samples: 500\n",
      "[OK] Subtraction test samples: 500\n",
      "[ACT] Extracting activations for ADDITION...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc40d55fdfb84136b268bc4219a22d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ADD S46 Extracting activations:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cee3c2235148dbb5f0382341086fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MULT S46 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057206ef6565483296412ef773708612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SUB S46 Extracting activations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROBE] Start layer-wise probing (0..28)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fbbc87a0124130b2c08cc5421a4a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Probing Layers S46:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Layer-wise probing finished for Seed 46.\n",
      "\n",
      "[AGG] Computing final statistics...\n",
      "ADDITION Test Accuracy: Mean=0.1290, 95.0% CI=(0.1246, 0.1333), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.0596, 95.0% CI=(0.0079, 0.1113), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0728, 95.0% CI=(0.0515, 0.0941), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1226, 95.0% CI=(0.1064, 0.1387), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.0604, 95.0% CI=(0.0185, 0.1023), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1096, 95.0% CI=(0.0272, 0.1920), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1378, 95.0% CI=(0.1139, 0.1616), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1052, 95.0% CI=(0.0819, 0.1285), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0616, 95.0% CI=(0.0001, 0.1231), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1370, 95.0% CI=(0.1276, 0.1463), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.0912, 95.0% CI=(0.0153, 0.1671), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0568, 95.0% CI=(0.0047, 0.1089), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1338, 95.0% CI=(0.1151, 0.1524), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.0680, 95.0% CI=(0.0272, 0.1088), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0872, 95.0% CI=(-0.0336, 0.2080), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1557, 95.0% CI=(0.1325, 0.1788), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.0912, 95.0% CI=(0.0809, 0.1015), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0968, 95.0% CI=(0.0285, 0.1651), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1528, 95.0% CI=(0.1164, 0.1892), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1228, 95.0% CI=(0.0860, 0.1596), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0916, 95.0% CI=(0.0110, 0.1722), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1608, 95.0% CI=(0.1325, 0.1891), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1504, 95.0% CI=(0.1242, 0.1766), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1464, 95.0% CI=(0.0552, 0.2376), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1670, 95.0% CI=(0.1380, 0.1961), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1136, 95.0% CI=(0.0670, 0.1602), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0800, 95.0% CI=(-0.0018, 0.1618), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1797, 95.0% CI=(0.1646, 0.1947), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1444, 95.0% CI=(0.0997, 0.1891), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0772, 95.0% CI=(0.0195, 0.1349), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1850, 95.0% CI=(0.1523, 0.2176), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.0828, 95.0% CI=(0.0539, 0.1117), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0508, 95.0% CI=(0.0256, 0.0760), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1859, 95.0% CI=(0.1756, 0.1963), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1044, 95.0% CI=(0.0675, 0.1413), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1820, 95.0% CI=(0.0875, 0.2765), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1811, 95.0% CI=(0.1604, 0.2019), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1316, 95.0% CI=(0.1112, 0.1520), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1164, 95.0% CI=(0.0586, 0.1742), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1861, 95.0% CI=(0.1714, 0.2007), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1348, 95.0% CI=(0.1025, 0.1671), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1256, 95.0% CI=(0.0471, 0.2041), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.1976, 95.0% CI=(0.1852, 0.2100), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1660, 95.0% CI=(0.1236, 0.2084), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0908, 95.0% CI=(0.0511, 0.1305), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2182, 95.0% CI=(0.1921, 0.2444), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1436, 95.0% CI=(0.0851, 0.2021), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0956, 95.0% CI=(0.0217, 0.1695), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2067, 95.0% CI=(0.1801, 0.2334), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1696, 95.0% CI=(0.1119, 0.2273), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1500, 95.0% CI=(0.0938, 0.2062), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2333, 95.0% CI=(0.2062, 0.2604), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.2064, 95.0% CI=(0.1649, 0.2479), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1896, 95.0% CI=(0.1040, 0.2752), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2362, 95.0% CI=(0.1924, 0.2800), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.2128, 95.0% CI=(0.1681, 0.2575), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1664, 95.0% CI=(0.0922, 0.2406), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2754, 95.0% CI=(0.2634, 0.2874), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.2064, 95.0% CI=(0.1488, 0.2640), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1212, 95.0% CI=(0.0472, 0.1952), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2838, 95.0% CI=(0.2588, 0.3089), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1972, 95.0% CI=(0.1727, 0.2217), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1236, 95.0% CI=(0.0908, 0.1564), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.2587, 95.0% CI=(0.2210, 0.2965), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.2108, 95.0% CI=(0.1544, 0.2672), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1132, 95.0% CI=(0.0573, 0.1691), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.3282, 95.0% CI=(0.3064, 0.3499), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.1908, 95.0% CI=(0.1735, 0.2081), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.1204, 95.0% CI=(0.0533, 0.1875), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.3701, 95.0% CI=(0.3427, 0.3975), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.2008, 95.0% CI=(0.1432, 0.2584), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.0972, 95.0% CI=(0.0424, 0.1520), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.6618, 95.0% CI=(0.6281, 0.6954), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.2528, 95.0% CI=(0.2164, 0.2892), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.3456, 95.0% CI=(0.2830, 0.4082), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.6760, 95.0% CI=(0.6470, 0.7050), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.3928, 95.0% CI=(0.3609, 0.4247), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.4652, 95.0% CI=(0.4128, 0.5176), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.6837, 95.0% CI=(0.6660, 0.7013), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.5024, 95.0% CI=(0.4399, 0.5649), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.4700, 95.0% CI=(0.4071, 0.5329), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.6752, 95.0% CI=(0.6410, 0.7094), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.4644, 95.0% CI=(0.4011, 0.5277), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.4504, 95.0% CI=(0.4000, 0.5008), N_valid_runs=5\n",
      "ADDITION Test Accuracy: Mean=0.6533, 95.0% CI=(0.6247, 0.6819), N_valid_runs=5\n",
      "Cross-Task Accuracy (MULT): Mean=0.4596, 95.0% CI=(0.3903, 0.5289), N_valid_runs=5\n",
      "Cross-Task Accuracy (SUB): Mean=0.4148, 95.0% CI=(0.3591, 0.4705), N_valid_runs=5\n",
      "[SAVE] Plot saved: ./experiment_hundreds_CI_20250909_164549/Qwen2.5-7B-Instruct/Qwen2.5-7B-Instruct_mean_probe_accuracy_CI_20250909_164549.pdf\n",
      "[SAVE] Plot saved: ./experiment_hundreds_CI_20250909_164549/Qwen2.5-7B-Instruct/Qwen2.5-7B-Instruct_mean_probe_accuracy_CI_20250909_164549.png\n",
      "[LOG] Aggregated log: ./experiment_hundreds_CI_20250909_164549/Qwen2.5-7B-Instruct/AGGREGATED_probe_log_Qwen2.5-7B-Instruct_20250909_164549.txt\n",
      "[OK ] Model /root/autodl-tmp/Qwen2.5-7B-Instruct finished; results at: ./experiment_hundreds_CI_20250909_164549/Qwen2.5-7B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Multi-model + adaptive layer count + per-model subdirectory saving version\n",
    "\n",
    "# --- Imports ---\n",
    "import os, re, math, random, datetime, collections, gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "# ============ 0. Global config (edit as needed) ============\n",
    "# Support multiple HF repo IDs or local paths\n",
    "MODELS = [\n",
    "        #\"/root/autodl-tmp/llama\",\n",
    "        #\"/root/autodl-tmp/Mistral\",\n",
    "        #\"/root/autodl-tmp/AceMath\",\n",
    "        \"/root/autodl-tmp/Qwen2.5-Math-7B\",\n",
    "        \"/root/autodl-tmp/Qwen2.5-7B-Instruct\"\n",
    "    ]\n",
    "\n",
    "DEVICE_ID = 0\n",
    "DEVICE = torch.device(f\"cuda:{DEVICE_ID}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Experiment & training settings\n",
    "N_SAMPLES_PER_DIGIT = 500\n",
    "BATCH_SIZE_PROBE = 64\n",
    "NUM_EPOCHS_PROBE = 5\n",
    "LEARNING_RATE_PROBE = 0.001\n",
    "HIDDEN_DIM_FACTOR = 1\n",
    "TEST_SPLIT_SIZE = 0.25\n",
    "RANDOM_SEED_BASE = 42\n",
    "N_REPETITIONS = 5\n",
    "CONFIDENCE_LEVEL = 0.95\n",
    "\n",
    "# Data generation settings (target: hundreds digit)\n",
    "ADD_MIN_SUM = 100\n",
    "N_MULT_TEST_SAMPLES = 500\n",
    "MULT_MIN_PRODUCT = 100\n",
    "MULT_MAX_PRODUCT = 999\n",
    "N_SUB_TEST_SAMPLES = 500\n",
    "SUB_MIN_DIFFERENCE = 100\n",
    "SUB_MAX_A = 999\n",
    "\n",
    "# Auto layer probing strategy:\n",
    "# - \"auto\": automatically use [0 .. num_hidden_layers] (including embedding layer 0)\n",
    "# - You can also change to a specific list such as [1..num_hidden_layers] to probe only blocks:\n",
    "#   modify one line inside run_experiment_for_model\n",
    "GLOBAL_LAYERS_TO_PROBE = \"auto\"\n",
    "\n",
    "# --- Main experiment directory ---\n",
    "experiment_timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "MAIN_EXPERIMENT_DIR = f\"./experiment_hundreds_CI_{experiment_timestamp}\"\n",
    "os.makedirs(MAIN_EXPERIMENT_DIR, exist_ok=True)\n",
    "print(f\"[INIT] Main experiment directory: {MAIN_EXPERIMENT_DIR}\")\n",
    "print(f\"[INIT] Using device: {DEVICE}\")\n",
    "\n",
    "# ============ 1. Utility functions ============\n",
    "def sanitize_model_id(model_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Make a safe folder name from a model id:\n",
    "    - Strip leading/trailing slashes\n",
    "    - Replace non-alphanumeric and . - _ with '_'\n",
    "    \"\"\"\n",
    "    base = model_id.strip().rstrip(\"/\")\n",
    "    # Use basename (for \"org/name\" -> \"name\"; for local path -> last directory)\n",
    "    base = os.path.basename(base)\n",
    "    safe = re.sub(r\"[^0-9A-Za-z._-]+\", \"_\", base)\n",
    "    return safe or \"model\"\n",
    "\n",
    "def set_seed(seed_value: int):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def format_add_prompt(a, b): return f\"Calculate: {a}+{b} = \"\n",
    "def format_mult_prompt(a, b): return f\"Calculate: {a}x{b} = \"\n",
    "def format_sub_prompt(a, b): return f\"Calculate: {a}-{b} = \"\n",
    "\n",
    "def get_layers_to_probe(model, mode=\"auto\"):\n",
    "    \"\"\"\n",
    "    Return a list of layer indices for indexing hidden_states.\n",
    "    In HF models, hidden_states[0] is the embedding; 1..N are block outputs.\n",
    "    \"\"\"\n",
    "    if mode == \"auto\":\n",
    "        num_layers = getattr(model.config, \"num_hidden_layers\", None)\n",
    "        if isinstance(num_layers, int) and num_layers > 0:\n",
    "            return list(range(0, num_layers + 1))  # include embedding layer\n",
    "        # Fallback: run a dummy forward to check length\n",
    "        tok = AutoTokenizer.from_pretrained(\"gpt2\")  # fallback only; not actually used\n",
    "        with torch.no_grad():\n",
    "            outs = model(**tok(\"test\", return_tensors=\"pt\"))\n",
    "        return list(range(0, len(outs.hidden_states)))\n",
    "    elif isinstance(mode, (list, tuple)):\n",
    "        return list(mode)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported GLOBAL_LAYERS_TO_PROBE setting.\")\n",
    "\n",
    "# --- Activation extraction ---\n",
    "def get_activations(prompts, layers_to_probe, current_model, current_tokenizer, batch_size=8, desc_prefix=\"\"):\n",
    "    from tqdm.auto import tqdm\n",
    "    activations = {layer: [] for layer in layers_to_probe}\n",
    "    current_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(prompts), batch_size), desc=f\"{desc_prefix} Extracting activations\"):\n",
    "            batch_prompts = prompts[i : i + batch_size]\n",
    "            try:\n",
    "                inputs = current_tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=64).to(DEVICE)\n",
    "                outputs = current_model(**inputs)\n",
    "                hidden_states = outputs.hidden_states\n",
    "                sequence_lengths = inputs.attention_mask.sum(dim=1)\n",
    "                last_token_indices = sequence_lengths - 1\n",
    "                for layer_idx in layers_to_probe:\n",
    "                    if layer_idx < 0 or layer_idx >= len(hidden_states):\n",
    "                        continue\n",
    "                    layer_hidden_states = hidden_states[layer_idx]\n",
    "                    batch_indices = torch.arange(layer_hidden_states.size(0), device=DEVICE)\n",
    "                    last_token_activations = layer_hidden_states[batch_indices, last_token_indices, :]\n",
    "                    activations[layer_idx].append(last_token_activations.to(torch.float32).cpu().numpy())\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Batch {i} ({desc_prefix}) failed: {e}\")\n",
    "    final_activations = {}\n",
    "    for layer in layers_to_probe:\n",
    "        if activations[layer]:\n",
    "            try:\n",
    "                final_activations[layer] = np.concatenate(activations[layer], axis=0)\n",
    "            except ValueError as e:\n",
    "                print(f\"[WARN] Layer {layer} concatenation failed: {e} | shapes: {[a.shape for a in activations[layer]]}\")\n",
    "                final_activations[layer] = np.array([])\n",
    "        else:\n",
    "            final_activations[layer] = np.array([])\n",
    "    return final_activations\n",
    "\n",
    "# --- Linear probe ---\n",
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, in_dim: int, n_classes: int):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, n_classes)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# ============ 2. Full pipeline for a single model ============\n",
    "def run_experiment_for_model(model_id: str):\n",
    "    safe_name = sanitize_model_id(model_id)\n",
    "    model_dir = os.path.join(MAIN_EXPERIMENT_DIR, safe_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    aggregated_log_filename = os.path.join(model_dir, f\"AGGREGATED_probe_log_{safe_name}_{experiment_timestamp}.txt\")\n",
    "    if os.path.exists(aggregated_log_filename):\n",
    "        os.remove(aggregated_log_filename)\n",
    "\n",
    "    # Load model & tokenizer\n",
    "    print(f\"\\n===== Loading model: {model_id} =====\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        output_hidden_states=True,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=None  # we manually .to(DEVICE)\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    if tokenizer.pad_token is None:\n",
    "        print(\"[INFO] Tokenizer has no pad_token; using eos_token as pad.\")\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = 'left'\n",
    "    print(\"[OK] Model loaded.\")\n",
    "\n",
    "    # Adaptive layers\n",
    "    layers_to_probe = get_layers_to_probe(model, GLOBAL_LAYERS_TO_PROBE)\n",
    "    print(f\"[INFO] Layers to probe (first 5 shown): {layers_to_probe[:5]}... total {len(layers_to_probe)} layers (including embedding layer 0).\")\n",
    "\n",
    "    # Store results across repetitions\n",
    "    overall_aggregated_results = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "\n",
    "    # ========= Repeated experiments =========\n",
    "    for rep_idx in range(N_REPETITIONS):\n",
    "        current_seed = RANDOM_SEED_BASE + rep_idx\n",
    "        set_seed(current_seed)\n",
    "        print(f\"\\n--- Repetition {rep_idx + 1}/{N_REPETITIONS} | Seed = {current_seed} ---\")\n",
    "\n",
    "        # Run directory for this repetition\n",
    "        run_dir = os.path.join(model_dir, f\"run_{rep_idx}_seed_{current_seed}\")\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "        PROBE_SAVE_DIR_RUN = os.path.join(run_dir, \"probe_models_hundreds\")\n",
    "        os.makedirs(PROBE_SAVE_DIR_RUN, exist_ok=True)\n",
    "        run_log_filename = os.path.join(run_dir, f\"run_log_{experiment_timestamp}.txt\")\n",
    "        if os.path.exists(run_log_filename):\n",
    "            os.remove(run_log_filename)\n",
    "\n",
    "        with open(aggregated_log_filename, \"a\") as agg_f:\n",
    "            agg_f.write(f\"\\n--- Repetition {rep_idx + 1}/{N_REPETITIONS} with Seed {current_seed} ---\\n\")\n",
    "\n",
    "        # --- Generate addition data (target: hundreds digit) ---\n",
    "        n_add_total_target = N_SAMPLES_PER_DIGIT * 10\n",
    "        n_add_to_generate_initial = n_add_total_target * 30\n",
    "        potential_add_samples = []\n",
    "        attempts_add = 0\n",
    "        max_attempts_add = n_add_to_generate_initial * 3\n",
    "        while len(potential_add_samples) < n_add_to_generate_initial and attempts_add < max_attempts_add:\n",
    "            a = random.randint(1, 899); b = random.randint(1, 899)\n",
    "            s = a + b\n",
    "            if s >= ADD_MIN_SUM:\n",
    "                potential_add_samples.append({'a': a, 'b': b, 'sum': s})\n",
    "            attempts_add += 1\n",
    "        samples_by_hundreds_add = collections.defaultdict(list)\n",
    "        for item in potential_add_samples:\n",
    "            hd = (item['sum'] // 100) % 10\n",
    "            samples_by_hundreds_add[hd].append(item)\n",
    "\n",
    "        all_add_samples_final_run = []\n",
    "        for digit_val in range(10):\n",
    "            available = samples_by_hundreds_add[digit_val]\n",
    "            n_to_take = min(N_SAMPLES_PER_DIGIT, len(available))\n",
    "            if len(available) < N_SAMPLES_PER_DIGIT:\n",
    "                print(f\"[WARN][Seed {current_seed}] Addition hundreds digit {digit_val} has only {len(available)} samples.\")\n",
    "            if not available:\n",
    "                print(f\"[ERR ][Seed {current_seed}] Addition hundreds digit {digit_val} has no samples.\")\n",
    "                continue\n",
    "            random.shuffle(available)\n",
    "            selected = available[:n_to_take]\n",
    "            for sample in selected:\n",
    "                sample['label'] = digit_val\n",
    "                sample['prompt'] = format_add_prompt(sample['a'], sample['b'])\n",
    "            all_add_samples_final_run.extend(selected)\n",
    "        random.shuffle(all_add_samples_final_run)\n",
    "        print(f\"[OK] Total addition train+test samples: {len(all_add_samples_final_run)}\")\n",
    "        if not all_add_samples_final_run:\n",
    "            with open(aggregated_log_filename, \"a\") as agg_f:\n",
    "                agg_f.write(\"CRITICAL ERROR: No ADDITION samples. Repetition skipped.\\n\")\n",
    "            with open(run_log_filename, \"a\") as run_f:\n",
    "                run_f.write(\"CRITICAL ERROR: No ADDITION samples. Repetition skipped.\\n\")\n",
    "            continue\n",
    "\n",
    "        # Multiplication test set\n",
    "        mult_samples_test_run = []\n",
    "        attempts_mult = 0; max_attempts_mult = N_MULT_TEST_SAMPLES * 50\n",
    "        min_factor = 2; max_factor = 99\n",
    "        while len(mult_samples_test_run) < N_MULT_TEST_SAMPLES and attempts_mult < max_attempts_mult:\n",
    "            attempts_mult += 1\n",
    "            a = random.randint(min_factor, max_factor); b = random.randint(min_factor, max_factor)\n",
    "            p = a * b\n",
    "            if MULT_MIN_PRODUCT <= p <= MULT_MAX_PRODUCT:\n",
    "                hd = (p // 100) % 10\n",
    "                mult_samples_test_run.append({'a':a,'b':b,'product':p,'label':hd,'prompt':format_mult_prompt(a,b)})\n",
    "        if len(mult_samples_test_run) > N_MULT_TEST_SAMPLES:\n",
    "            random.shuffle(mult_samples_test_run)\n",
    "            mult_samples_test_run = mult_samples_test_run[:N_MULT_TEST_SAMPLES]\n",
    "        print(f\"[OK] Multiplication test samples: {len(mult_samples_test_run)}\")\n",
    "\n",
    "        # Subtraction test set\n",
    "        sub_samples_test_run = []\n",
    "        attempts_sub = 0; max_attempts_sub = N_SUB_TEST_SAMPLES * 100\n",
    "        while len(sub_samples_test_run) < N_SUB_TEST_SAMPLES and attempts_sub < max_attempts_sub:\n",
    "            attempts_sub += 1\n",
    "            a = random.randint(SUB_MIN_DIFFERENCE + 1, SUB_MAX_A)\n",
    "            max_b = a - SUB_MIN_DIFFERENCE\n",
    "            if max_b < 1: continue\n",
    "            b = random.randint(1, max_b)\n",
    "            d = a - b\n",
    "            if d >= SUB_MIN_DIFFERENCE:\n",
    "                hd = (d // 100) % 10\n",
    "                sub_samples_test_run.append({'a':a,'b':b,'difference':d,'label':hd,'prompt':format_sub_prompt(a,b)})\n",
    "        if len(sub_samples_test_run) > N_SUB_TEST_SAMPLES:\n",
    "            random.shuffle(sub_samples_test_run)\n",
    "            sub_samples_test_run = sub_samples_test_run[:N_SUB_TEST_SAMPLES]\n",
    "        print(f\"[OK] Subtraction test samples: {len(sub_samples_test_run)}\")\n",
    "\n",
    "        # --- Extract activations ---\n",
    "        from tqdm.auto import tqdm\n",
    "        print(\"[ACT] Extracting activations for ADDITION...\")\n",
    "        prompts_add_all_run = [s['prompt'] for s in all_add_samples_final_run]\n",
    "        activations_add_all_run = get_activations(prompts_add_all_run, layers_to_probe, model, tokenizer, batch_size=BATCH_SIZE_PROBE, desc_prefix=f\"ADD S{current_seed}\")\n",
    "\n",
    "        activations_mult_test_run = {}; y_mult_test_labels_run = np.array([])\n",
    "        if mult_samples_test_run:\n",
    "            prompts_mult_test_run = [s['prompt'] for s in mult_samples_test_run]\n",
    "            activations_mult_test_run = get_activations(prompts_mult_test_run, layers_to_probe, model, tokenizer, batch_size=BATCH_SIZE_PROBE, desc_prefix=f\"MULT S{current_seed}\")\n",
    "            y_mult_test_labels_run = np.array([s['label'] for s in mult_samples_test_run])\n",
    "\n",
    "        activations_sub_test_run = {}; y_sub_test_labels_run = np.array([])\n",
    "        if sub_samples_test_run:\n",
    "            prompts_sub_test_run = [s['prompt'] for s in sub_samples_test_run]\n",
    "            activations_sub_test_run = get_activations(prompts_sub_test_run, layers_to_probe, model, tokenizer, batch_size=BATCH_SIZE_PROBE, desc_prefix=f\"SUB S{current_seed}\")\n",
    "            y_sub_test_labels_run = np.array([s['label'] for s in sub_samples_test_run])\n",
    "\n",
    "        # --- Train & evaluate ---\n",
    "        y_add_all_run = np.array([s['label'] for s in all_add_samples_final_run])\n",
    "        print(f\"[PROBE] Start layer-wise probing ({min(layers_to_probe)}..{max(layers_to_probe)})\")\n",
    "\n",
    "        for layer in tqdm(layers_to_probe, desc=f\"Probing Layers S{current_seed}\"):\n",
    "            layer_results_run = {\"layer\": layer, \"accuracy_add\": np.nan, \"cross_accuracy_mult\": np.nan, \"cross_accuracy_sub\": np.nan, \"report_add\": \"Skipped\"}\n",
    "            if layer not in activations_add_all_run or activations_add_all_run[layer].shape[0] == 0:\n",
    "                with open(run_log_filename, \"a\") as f:\n",
    "                    f.write(f\"--- Layer {layer} ---\\nSkipped: No ADDITION activation data\\n{'-'*20}\\n\")\n",
    "                with open(aggregated_log_filename, \"a\") as agg_f:\n",
    "                    agg_f.write(f\"L{layer}: ADD No Act\\n\")\n",
    "                overall_aggregated_results[layer][\"accuracy_add\"].append(np.nan)\n",
    "                overall_aggregated_results[layer][\"cross_accuracy_mult\"].append(np.nan)\n",
    "                overall_aggregated_results[layer][\"cross_accuracy_sub\"].append(np.nan)\n",
    "                continue\n",
    "\n",
    "            X_add_all_layer_run = activations_add_all_run[layer]\n",
    "            if X_add_all_layer_run.shape[0] != len(y_add_all_run):\n",
    "                with open(run_log_filename, \"a\") as f:\n",
    "                    f.write(f\"--- Layer {layer} ---\\nSkipped: Mismatch activations/labels\\n{'-'*20}\\n\")\n",
    "                with open(aggregated_log_filename, \"a\") as agg_f:\n",
    "                    agg_f.write(f\"L{layer}: ADD Mismatch\\n\")\n",
    "                overall_aggregated_results[layer][\"accuracy_add\"].append(np.nan)\n",
    "                overall_aggregated_results[layer][\"cross_accuracy_mult\"].append(np.nan)\n",
    "                overall_aggregated_results[layer][\"cross_accuracy_sub\"].append(np.nan)\n",
    "                continue\n",
    "\n",
    "            unique_labels_run = np.unique(y_add_all_run)\n",
    "            if len(unique_labels_run) < 2:\n",
    "                with open(run_log_filename, \"a\") as f:\n",
    "                    f.write(f\"--- Layer {layer} ---\\nSkipped: Insufficient unique classes ({len(unique_labels_run)})\\n{'-'*20}\\n\")\n",
    "                with open(aggregated_log_filename, \"a\") as agg_f:\n",
    "                    agg_f.write(f\"L{layer}: ADD FewClasses\\n\")\n",
    "                overall_aggregated_results[layer][\"accuracy_add\"].append(np.nan)\n",
    "                overall_aggregated_results[layer][\"cross_accuracy_mult\"].append(np.nan)\n",
    "                overall_aggregated_results[layer][\"cross_accuracy_sub\"].append(np.nan)\n",
    "                continue\n",
    "\n",
    "            OUTPUT_DIM = 10\n",
    "            try:\n",
    "                X_add_train_run, X_add_test_run, y_add_train_run, y_add_test_run = train_test_split(\n",
    "                    X_add_all_layer_run, y_add_all_run, test_size=TEST_SPLIT_SIZE, random_state=current_seed, stratify=y_add_all_run\n",
    "                )\n",
    "            except ValueError as e_split:\n",
    "                with open(run_log_filename, \"a\") as f:\n",
    "                    f.write(f\"--- Layer {layer} ---\\nSkipped: Train/Test split error: {e_split}\\n{'-'*20}\\n\")\n",
    "                with open(aggregated_log_filename, \"a\") as agg_f:\n",
    "                    agg_f.write(f\"L{layer}: ADD SplitErr\\n\")\n",
    "                overall_aggregated_results[layer][\"accuracy_add\"].append(np.nan)\n",
    "                overall_aggregated_results[layer][\"cross_accuracy_mult\"].append(np.nan)\n",
    "                overall_aggregated_results[layer][\"cross_accuracy_sub\"].append(np.nan)\n",
    "                continue\n",
    "\n",
    "            X_add_train_run, y_add_train_run = shuffle(X_add_train_run, y_add_train_run, random_state=current_seed)\n",
    "            INPUT_DIM_run = X_add_train_run.shape[1]\n",
    "            HIDDEN_DIM_run = int(INPUT_DIM_run * HIDDEN_DIM_FACTOR)\n",
    "\n",
    "            probe = LinearProbe(INPUT_DIM_run, OUTPUT_DIM).to(DEVICE)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(probe.parameters(), lr=LEARNING_RATE_PROBE)\n",
    "\n",
    "            train_dataset = TensorDataset(torch.tensor(X_add_train_run, dtype=torch.float32).to(DEVICE),\n",
    "                                          torch.tensor(y_add_train_run, dtype=torch.long).to(DEVICE))\n",
    "            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_PROBE, shuffle=True)\n",
    "\n",
    "            probe.train()\n",
    "            for _ in range(NUM_EPOCHS_PROBE):\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    logits = probe(batch_X)\n",
    "                    loss = criterion(logits, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # Save the probe for this layer\n",
    "            layer_probe_dir = os.path.join(PROBE_SAVE_DIR_RUN, f\"layer_{layer}\")\n",
    "            os.makedirs(layer_probe_dir, exist_ok=True)\n",
    "            torch.save(probe.state_dict(), os.path.join(layer_probe_dir, \"state_dict.pt\"))\n",
    "\n",
    "            # ADD test\n",
    "            probe.eval()\n",
    "            with torch.no_grad():\n",
    "                logits = probe(torch.tensor(X_add_test_run, dtype=torch.float32).to(DEVICE))\n",
    "                _, pred_idx = torch.max(logits, 1)\n",
    "                y_pred = pred_idx.cpu().numpy()\n",
    "                y_true = torch.tensor(y_add_test_run, dtype=torch.long).cpu().numpy()\n",
    "                acc_add = accuracy_score(y_true, y_pred)\n",
    "                try:\n",
    "                    report_add = classification_report(\n",
    "                        y_true, y_pred, labels=list(range(OUTPUT_DIM)), digits=3, zero_division=0,\n",
    "                        target_names=[f\"Digit {i}\" for i in range(OUTPUT_DIM)]\n",
    "                    )\n",
    "                except ValueError as e:\n",
    "                    report_add = f\"Acc: {acc_add:.4f}, Report failed: {e}\"\n",
    "\n",
    "            layer_results_run[\"accuracy_add\"] = acc_add\n",
    "            layer_results_run[\"report_add\"] = report_add\n",
    "            overall_aggregated_results[layer][\"accuracy_add\"].append(acc_add)\n",
    "\n",
    "            # MULT transfer\n",
    "            acc_cross_mult = np.nan\n",
    "            if mult_samples_test_run and layer in activations_mult_test_run and activations_mult_test_run[layer].shape[0] > 0:\n",
    "                Xm = activations_mult_test_run[layer]\n",
    "                if Xm.shape[0] == len(y_mult_test_labels_run):\n",
    "                    with torch.no_grad():\n",
    "                        logits_m = probe(torch.tensor(Xm, dtype=torch.float32).to(DEVICE))\n",
    "                        _, pred_m = torch.max(logits_m, 1)\n",
    "                        acc_cross_mult = accuracy_score(y_mult_test_labels_run, pred_m.cpu().numpy())\n",
    "            layer_results_run[\"cross_accuracy_mult\"] = acc_cross_mult\n",
    "            overall_aggregated_results[layer][\"cross_accuracy_mult\"].append(acc_cross_mult)\n",
    "\n",
    "            # SUB transfer\n",
    "            acc_cross_sub = np.nan\n",
    "            if sub_samples_test_run and layer in activations_sub_test_run and activations_sub_test_run[layer].shape[0] > 0:\n",
    "                Xs = activations_sub_test_run[layer]\n",
    "                if Xs.shape[0] == len(y_sub_test_labels_run):\n",
    "                    with torch.no_grad():\n",
    "                        logits_s = probe(torch.tensor(Xs, dtype=torch.float32).to(DEVICE))\n",
    "                        _, pred_s = torch.max(logits_s, 1)\n",
    "                        acc_cross_sub = accuracy_score(y_sub_test_labels_run, pred_s.cpu().numpy())\n",
    "            layer_results_run[\"cross_accuracy_sub\"] = acc_cross_sub\n",
    "            overall_aggregated_results[layer][\"cross_accuracy_sub\"].append(acc_cross_sub)\n",
    "\n",
    "            # Logging\n",
    "            with open(run_log_filename, \"a\") as f_run:\n",
    "                f_run.write(f\"--- Layer {layer} ---\\n\")\n",
    "                f_run.write(f\"ADDITION Test Accuracy: {acc_add:.4f}\\n\")\n",
    "                f_run.write(f\"Cross-Task Accuracy (Mult): {acc_cross_mult:.4f}\\n\")\n",
    "                f_run.write(f\"Cross-Task Accuracy (Sub): {acc_cross_sub:.4f}\\n\")\n",
    "                f_run.write(f\"ADDITION Classification Report:\\n{report_add}\\n{'-'*20}\\n\")\n",
    "            with open(aggregated_log_filename, \"a\") as f_agg:\n",
    "                f_agg.write(f\"L{layer}: AddAcc={acc_add:.4f}, MultAcc={acc_cross_mult:.4f}, SubAcc={acc_cross_sub:.4f}\\n\")\n",
    "\n",
    "        print(f\"[DONE] Layer-wise probing finished for Seed {current_seed}.\")\n",
    "\n",
    "    # ========= Aggregate statistics + plot (per model) =========\n",
    "    print(\"\\n[AGG] Computing final statistics...\")\n",
    "    alpha = 1.0 - CONFIDENCE_LEVEL\n",
    "    with open(aggregated_log_filename, \"a\") as f_agg:\n",
    "        f_agg.write(\"\\n\\n--- Aggregated Statistics Across Runs ---\\n\")\n",
    "        f_agg.write(f\"Number of Repetitions: {N_REPETITIONS}, Confidence Level: {CONFIDENCE_LEVEL*100}%\\n\")\n",
    "\n",
    "    sorted_layers = sorted(list(overall_aggregated_results.keys()))\n",
    "    plot_data = {\n",
    "        \"layers\": sorted_layers,\n",
    "        \"add\": {\"mean\": [], \"ci_margin\": []},\n",
    "        \"mult\": {\"mean\": [], \"ci_margin\": []},\n",
    "        \"sub\": {\"mean\": [], \"ci_margin\": []}\n",
    "    }\n",
    "\n",
    "    for layer in sorted_layers:\n",
    "        with open(aggregated_log_filename, \"a\") as f_agg:\n",
    "            f_agg.write(f\"\\n--- Layer {layer} ---\\n\")\n",
    "        for metric_key, display_name, plot_key in [\n",
    "            (\"accuracy_add\", \"ADDITION Test Accuracy\", \"add\"),\n",
    "            (\"cross_accuracy_mult\", \"Cross-Task Accuracy (MULT)\", \"mult\"),\n",
    "            (\"cross_accuracy_sub\", \"Cross-Task Accuracy (SUB)\", \"sub\")\n",
    "        ]:\n",
    "            vals = np.array([v for v in overall_aggregated_results[layer][metric_key] if not np.isnan(v)])\n",
    "            mean_acc = np.nan\n",
    "            ci_lower = ci_upper = np.nan\n",
    "            ci_margin = 0.0\n",
    "            if len(vals) >= 2:\n",
    "                mean_acc = np.mean(vals)\n",
    "                se = scipy.stats.sem(vals)\n",
    "                if se > 0:\n",
    "                    lo, hi = scipy.stats.t.interval(CONFIDENCE_LEVEL, len(vals)-1, loc=mean_acc, scale=se)\n",
    "                    ci_lower, ci_upper = lo, hi\n",
    "                    ci_margin = (hi - lo) / 2\n",
    "                else:\n",
    "                    ci_lower = ci_upper = mean_acc\n",
    "                    ci_margin = 0.0\n",
    "            elif len(vals) == 1:\n",
    "                mean_acc = vals[0]\n",
    "            plot_data[plot_key][\"mean\"].append(mean_acc)\n",
    "            plot_data[plot_key][\"ci_margin\"].append(ci_margin)\n",
    "            line = f\"{display_name}: Mean={mean_acc:.4f}, {CONFIDENCE_LEVEL*100}% CI=({ci_lower:.4f}, {ci_upper:.4f}), N_valid_runs={len(vals)}\"\n",
    "            print(line)\n",
    "            with open(aggregated_log_filename, \"a\") as f_agg:\n",
    "                f_agg.write(line + \"\\n\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 14, 'font.family': 'serif', 'font.sans-serif': ['Arial'],\n",
    "        'axes.labelsize': 14, 'axes.titlesize': 20,\n",
    "        'xtick.labelsize': 12, 'ytick.labelsize': 12, 'legend.fontsize': 14,\n",
    "        'lines.linewidth': 1.8, 'lines.markersize': 6,\n",
    "        'axes.grid': True, 'grid.alpha': 0.5, 'grid.linestyle': ':',\n",
    "        'savefig.dpi': 600, 'savefig.format': 'pdf', 'savefig.bbox': 'tight',\n",
    "    })\n",
    "\n",
    "    # ADD\n",
    "    add_means = np.array(plot_data[\"add\"][\"mean\"])\n",
    "    add_cis = np.array(plot_data[\"add\"][\"ci_margin\"])\n",
    "    plt.plot(plot_data[\"layers\"], add_means, marker='o', linestyle='-', label='Mean Probe Accuracy on ADDITION')\n",
    "    plt.fill_between(plot_data[\"layers\"], add_means - add_cis, add_means + add_cis, alpha=0.2, label=f'{CONFIDENCE_LEVEL*100}% CI (ADD)')\n",
    "\n",
    "    # MULT\n",
    "    mult_means = np.array(plot_data[\"mult\"][\"mean\"])\n",
    "    mult_cis = np.array(plot_data[\"mult\"][\"ci_margin\"])\n",
    "    plt.plot(plot_data[\"layers\"], mult_means, marker='x', linestyle=':', label='Mean Probe Accuracy on MULTIPLICATION')\n",
    "    plt.fill_between(plot_data[\"layers\"], mult_means - mult_cis, mult_means + mult_cis, alpha=0.2, label=f'{CONFIDENCE_LEVEL*100}% CI (MULT)')\n",
    "\n",
    "    # SUB\n",
    "    sub_means = np.array(plot_data[\"sub\"][\"mean\"])\n",
    "    sub_cis = np.array(plot_data[\"sub\"][\"ci_margin\"])\n",
    "    plt.plot(plot_data[\"layers\"], sub_means, marker='^', linestyle='--', label='Mean Probe Accuracy on SUBTRACTION')\n",
    "    plt.fill_between(plot_data[\"layers\"], sub_means - sub_cis, sub_means + sub_cis, alpha=0.2, label=f'{CONFIDENCE_LEVEL*100}% CI (SUB)')\n",
    "\n",
    "    # Chance level\n",
    "    chance = 1.0 / 10\n",
    "    plt.axhline(y=chance, linestyle='-.', label=f'Chance Level ({chance:.2f}, 10 classes)')\n",
    "\n",
    "    plt.xlabel(f\"Model Layer Index ({safe_name})\")\n",
    "    plt.ylabel(\"Mean Probe Accuracy Score\")\n",
    "    plt.title(f\"[{safe_name}] Mean Probe Performance & {int(CONFIDENCE_LEVEL*100)}% CI (N={N_REPETITIONS})\")\n",
    "    if plot_data[\"layers\"]:\n",
    "        plt.xticks(plot_data[\"layers\"])\n",
    "    plt.ylim(0.0, 1.05)\n",
    "    plt.legend(loc='best', fontsize='small')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plot_pdf = os.path.join(model_dir, f\"{safe_name}_mean_probe_accuracy_CI_{experiment_timestamp}.pdf\")\n",
    "    plot_png = os.path.join(model_dir, f\"{safe_name}_mean_probe_accuracy_CI_{experiment_timestamp}.png\")\n",
    "    plt.savefig(plot_pdf, format='pdf', bbox_inches='tight')\n",
    "    plt.savefig(plot_png, bbox_inches='tight')\n",
    "    print(f\"[SAVE] Plot saved: {plot_pdf}\\n[SAVE] Plot saved: {plot_png}\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"[LOG] Aggregated log: {aggregated_log_filename}\")\n",
    "    print(f\"[OK ] Model {model_id} finished; results at: {model_dir}\")\n",
    "\n",
    "    # Free GPU memory\n",
    "    del model\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception:\n",
    "        pass\n",
    "    gc.collect()\n",
    "\n",
    "# ============ 3. Entry point: run multiple models in sequence ============\n",
    "if __name__ == \"__main__\":\n",
    "    if not MODELS:\n",
    "        print(\"Please provide at least one model path or HF repo id in MODELS.\")\n",
    "    for mid in MODELS:\n",
    "        try:\n",
    "            run_experiment_for_model(mid)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Model {mid} failed to run: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac225827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
