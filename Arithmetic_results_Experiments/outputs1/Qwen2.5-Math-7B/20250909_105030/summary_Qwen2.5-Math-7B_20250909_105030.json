{
  "model": "/root/autodl-tmp/Qwen2.5-Math-7B",
  "model_short": "Qwen2.5-Math-7B",
  "timestamp": "20250909_105030",
  "device": "cuda:0",
  "hyper_params": {
    "MODEL_NAMES": [
      "/root/autodl-tmp/llama",
      "/root/autodl-tmp/Mistral",
      "/root/autodl-tmp/Qwen2.5-Math-7B",
      "/root/autodl-tmp/AceMath",
      "/root/autodl-tmp/Qwen2.5-7B-Instruct"
    ],
    "N_REPETITIONS": 5,
    "BASE_SEED": 42,
    "PROBE_TYPE": "linear",
    "PROBE_MLP_HIDDEN_DIM": 4096,
    "N_PROBE_EPOCHS": 5,
    "PROBE_LR": 0.001,
    "PROBE_BATCH_SIZE": 64,
    "TEST_SPLIT_RATIO": 0.2,
    "GENERATION_BATCH_SIZE": 500,
    "GEN_MAX_NEW_TOKENS": 3,
    "GEN_DO_SAMPLE": false,
    "TOK_MAX_LENGTH": 60,
    "TOK_PADDING_SIDE": "left",
    "SUM_RANGES_CONFIG": [
      {
        "label": "500-509",
        "start": 500,
        "count": 10
      },
      {
        "label": "600-609",
        "start": 600,
        "count": 10
      },
      {
        "label": "700-709",
        "start": 700,
        "count": 10
      },
      {
        "label": "800-809",
        "start": 800,
        "count": 10
      },
      {
        "label": "900-909",
        "start": 900,
        "count": 10
      }
    ],
    "N_SAMPLES_PER_SUM": 400,
    "MIN_SAMPLES_PER_CLASS_FOR_PROBING": 5,
    "MIN_ADDEND_VAL": 100,
    "A_BOUND_LOW_FRAC": 0.25,
    "A_BOUND_HIGH_FRAC": 0.75,
    "MAX_ATTEMPTS_MULTIPLIER": 20,
    "ACTIVATIONS_BATCH_SIZE": 256,
    "LOG_TO_CONSOLE": false,
    "TQDM_DISABLED": true,
    "SUPPRESS_WARNINGS": true
  },
  "probe_type": "linear",
  "probe_epochs": 5,
  "probe_lr": 0.001,
  "probe_batch_size": 64,
  "generation_batch_size": 500,
  "sum_ranges_config": [
    {
      "label": "500-509",
      "start": 500,
      "count": 10
    },
    {
      "label": "600-609",
      "start": 600,
      "count": 10
    },
    {
      "label": "700-709",
      "start": 700,
      "count": 10
    },
    {
      "label": "800-809",
      "start": 800,
      "count": 10
    },
    {
      "label": "900-909",
      "start": 900,
      "count": 10
    }
  ],
  "n_samples_per_sum": 400,
  "test_split_ratio": 0.2,
  "layers_to_probe": [
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18,
    19,
    20,
    21,
    22,
    23,
    24,
    25,
    26,
    27,
    28
  ],
  "logical_num_layers": 28,
  "hidden_states_tuple_len": 29,
  "results": {
    "500-509": {
      "target_sums": [
        500,
        501,
        502,
        503,
        504,
        505,
        506,
        507,
        508,
        509
      ],
      "n_classes": 10,
      "generation_accuracies_reps": [
        0.20925,
        0.2175,
        0.2105,
        0.21125,
        0.21125
      ],
      "original_sample_counts_reps": [
        4000,
        4000,
        4000,
        4000,
        4000
      ],
      "filtered_sample_counts_reps": [
        837,
        870,
        842,
        845,
        845
      ],
      "probe_accuracies_per_layer_reps": {
        "1": [
          0.10714285714285714,
          0.1206896551724138,
          0.1242603550295858,
          0.14792899408284024,
          0.15976331360946747
        ],
        "2": [
          0.09523809523809523,
          0.15517241379310345,
          0.1242603550295858,
          0.15384615384615385,
          0.11242603550295859
        ],
        "3": [
          0.1130952380952381,
          0.12643678160919541,
          0.13609467455621302,
          0.13609467455621302,
          0.10650887573964497
        ],
        "4": [
          0.08928571428571429,
          0.1206896551724138,
          0.09467455621301775,
          0.15384615384615385,
          0.13609467455621302
        ],
        "5": [
          0.09523809523809523,
          0.16091954022988506,
          0.15384615384615385,
          0.14792899408284024,
          0.11834319526627218
        ],
        "6": [
          0.17261904761904762,
          0.15517241379310345,
          0.14792899408284024,
          0.15384615384615385,
          0.09467455621301775
        ],
        "7": [
          0.10119047619047619,
          0.14367816091954022,
          0.11242603550295859,
          0.10059171597633136,
          0.1952662721893491
        ],
        "8": [
          0.19642857142857142,
          0.21264367816091953,
          0.15976331360946747,
          0.17159763313609466,
          0.10059171597633136
        ],
        "9": [
          0.15476190476190477,
          0.1724137931034483,
          0.14792899408284024,
          0.15976331360946747,
          0.1952662721893491
        ],
        "10": [
          0.2261904761904762,
          0.1896551724137931,
          0.21301775147928995,
          0.20710059171597633,
          0.20710059171597633
        ],
        "11": [
          0.27380952380952384,
          0.1781609195402299,
          0.22485207100591717,
          0.20118343195266272,
          0.2485207100591716
        ],
        "12": [
          0.25595238095238093,
          0.21264367816091953,
          0.1893491124260355,
          0.21301775147928995,
          0.2781065088757396
        ],
        "13": [
          0.25,
          0.27011494252873564,
          0.28402366863905326,
          0.2781065088757396,
          0.3136094674556213
        ],
        "14": [
          0.30357142857142855,
          0.25862068965517243,
          0.22485207100591717,
          0.23668639053254437,
          0.22485207100591717
        ],
        "15": [
          0.31547619047619047,
          0.3448275862068966,
          0.28402366863905326,
          0.3136094674556213,
          0.1834319526627219
        ],
        "16": [
          0.30952380952380953,
          0.3218390804597701,
          0.35502958579881655,
          0.2485207100591716,
          0.23076923076923078
        ],
        "17": [
          0.2976190476190476,
          0.3333333333333333,
          0.3076923076923077,
          0.35502958579881655,
          0.26627218934911245
        ],
        "18": [
          0.35714285714285715,
          0.3448275862068966,
          0.5443786982248521,
          0.4437869822485207,
          0.3905325443786982
        ],
        "19": [
          0.5833333333333334,
          0.5344827586206896,
          0.5502958579881657,
          0.5266272189349113,
          0.5857988165680473
        ],
        "20": [
          0.6666666666666666,
          0.632183908045977,
          0.7041420118343196,
          0.591715976331361,
          0.5562130177514792
        ],
        "21": [
          0.48214285714285715,
          0.5747126436781609,
          0.6923076923076923,
          0.5739644970414202,
          0.5680473372781065
        ],
        "22": [
          0.5595238095238095,
          0.6091954022988506,
          0.5502958579881657,
          0.48520710059171596,
          0.5443786982248521
        ],
        "23": [
          0.5595238095238095,
          0.5632183908045977,
          0.6272189349112426,
          0.6035502958579881,
          0.5739644970414202
        ],
        "24": [
          0.5714285714285714,
          0.5747126436781609,
          0.5502958579881657,
          0.7218934911242604,
          0.5266272189349113
        ],
        "25": [
          0.6309523809523809,
          0.7011494252873564,
          0.6982248520710059,
          0.650887573964497,
          0.5621301775147929
        ],
        "26": [
          0.6547619047619048,
          0.6379310344827587,
          0.6804733727810651,
          0.6804733727810651,
          0.6094674556213018
        ],
        "27": [
          0.6726190476190477,
          0.6839080459770115,
          0.650887573964497,
          0.6863905325443787,
          0.6923076923076923
        ],
        "28": [
          0.6428571428571429,
          0.6494252873563219,
          0.6094674556213018,
          0.6390532544378699,
          0.6094674556213018
        ]
      },
      "best_layer_indices_reps": [
        27,
        25,
        20,
        24,
        27
      ],
      "best_layer_accuracies_reps": [
        0.6726190476190477,
        0.7011494252873564,
        0.7041420118343196,
        0.7218934911242604,
        0.6923076923076923
      ],
      "best_layer_reports_reps": [
        "              precision    recall  f1-score   support\n\n           0       1.00      0.94      0.97        18\n           1       0.61      0.79      0.69        14\n           2       0.52      0.93      0.67        14\n           3       0.53      0.56      0.55        16\n           4       0.67      0.38      0.48        16\n           5       0.53      0.42      0.47        19\n           6       0.44      0.25      0.32        16\n           7       0.77      0.81      0.79        21\n           8       0.69      0.73      0.71        15\n           9       0.85      0.89      0.87        19\n\n    accuracy                           0.67       168\n   macro avg       0.66      0.67      0.65       168\nweighted avg       0.67      0.67      0.66       168\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        18\n           1       0.80      0.27      0.40        15\n           2       0.83      0.77      0.80        13\n           3       0.46      0.81      0.59        16\n           4       0.76      0.72      0.74        18\n           5       0.83      0.56      0.67        18\n           6       0.47      0.89      0.62        19\n           7       0.68      0.62      0.65        21\n           8       1.00      0.47      0.64        17\n           9       0.84      0.84      0.84        19\n\n    accuracy                           0.70       174\n   macro avg       0.77      0.70      0.70       174\nweighted avg       0.77      0.70      0.70       174\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        19\n           1       0.91      0.71      0.80        14\n           2       0.69      0.69      0.69        13\n           3       0.41      0.75      0.53        16\n           4       0.62      1.00      0.77        20\n           5       0.64      0.76      0.70        21\n           6       0.57      0.25      0.35        16\n           7       1.00      0.29      0.45        17\n           8       0.73      0.79      0.76        14\n           9       1.00      0.68      0.81        19\n\n    accuracy                           0.70       169\n   macro avg       0.76      0.69      0.69       169\nweighted avg       0.76      0.70      0.69       169\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        19\n           1       0.79      0.79      0.79        14\n           2       0.73      0.62      0.67        13\n           3       0.88      0.93      0.90        15\n           4       0.50      0.83      0.62        18\n           5       0.67      0.56      0.61        25\n           6       1.00      0.43      0.60        14\n           7       0.62      0.59      0.61        17\n           8       0.72      0.76      0.74        17\n           9       0.67      0.71      0.69        17\n\n    accuracy                           0.72       169\n   macro avg       0.76      0.72      0.72       169\nweighted avg       0.75      0.72      0.72       169\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        19\n           1       0.90      0.56      0.69        16\n           2       0.64      0.75      0.69        12\n           3       0.52      0.71      0.60        17\n           4       0.78      0.47      0.58        15\n           5       0.77      0.48      0.59        21\n           6       0.82      0.60      0.69        15\n           7       0.65      0.65      0.65        17\n           8       0.58      0.82      0.68        17\n           9       0.59      0.85      0.69        20\n\n    accuracy                           0.69       169\n   macro avg       0.72      0.69      0.69       169\nweighted avg       0.73      0.69      0.69       169\n"
      ]
    },
    "600-609": {
      "target_sums": [
        600,
        601,
        602,
        603,
        604,
        605,
        606,
        607,
        608,
        609
      ],
      "n_classes": 10,
      "generation_accuracies_reps": [
        0.372,
        0.3725,
        0.37775,
        0.3665,
        0.3775
      ],
      "original_sample_counts_reps": [
        4000,
        4000,
        4000,
        4000,
        4000
      ],
      "filtered_sample_counts_reps": [
        1488,
        1490,
        1511,
        1466,
        1510
      ],
      "probe_accuracies_per_layer_reps": {
        "1": [
          0.09731543624161074,
          0.10738255033557047,
          0.1188118811881188,
          0.18027210884353742,
          0.10927152317880795
        ],
        "2": [
          0.1040268456375839,
          0.12080536912751678,
          0.09570957095709572,
          0.11564625850340136,
          0.12582781456953643
        ],
        "3": [
          0.11073825503355705,
          0.1174496644295302,
          0.1188118811881188,
          0.17006802721088435,
          0.10927152317880795
        ],
        "4": [
          0.13087248322147652,
          0.16778523489932887,
          0.132013201320132,
          0.09523809523809523,
          0.11589403973509933
        ],
        "5": [
          0.174496644295302,
          0.14093959731543623,
          0.1617161716171617,
          0.15306122448979592,
          0.12251655629139073
        ],
        "6": [
          0.11409395973154363,
          0.12751677852348994,
          0.1848184818481848,
          0.1054421768707483,
          0.15894039735099338
        ],
        "7": [
          0.1174496644295302,
          0.14429530201342283,
          0.10231023102310231,
          0.1360544217687075,
          0.16887417218543047
        ],
        "8": [
          0.14429530201342283,
          0.17785234899328858,
          0.18811881188118812,
          0.19047619047619047,
          0.1390728476821192
        ],
        "9": [
          0.13758389261744966,
          0.1644295302013423,
          0.16831683168316833,
          0.16326530612244897,
          0.2251655629139073
        ],
        "10": [
          0.24161073825503357,
          0.2483221476510067,
          0.2607260726072607,
          0.22789115646258504,
          0.27483443708609273
        ],
        "11": [
          0.22483221476510068,
          0.27181208053691275,
          0.30363036303630364,
          0.24149659863945577,
          0.28807947019867547
        ],
        "12": [
          0.2181208053691275,
          0.2483221476510067,
          0.21782178217821782,
          0.2687074829931973,
          0.19536423841059603
        ],
        "13": [
          0.26174496644295303,
          0.2684563758389262,
          0.2706270627062706,
          0.282312925170068,
          0.31788079470198677
        ],
        "14": [
          0.2651006711409396,
          0.3053691275167785,
          0.3465346534653465,
          0.2585034013605442,
          0.26158940397350994
        ],
        "15": [
          0.3053691275167785,
          0.3087248322147651,
          0.28052805280528054,
          0.282312925170068,
          0.30132450331125826
        ],
        "16": [
          0.30201342281879195,
          0.22483221476510068,
          0.35313531353135313,
          0.2755102040816326,
          0.31456953642384106
        ],
        "17": [
          0.35570469798657717,
          0.32550335570469796,
          0.31353135313531355,
          0.40476190476190477,
          0.33774834437086093
        ],
        "18": [
          0.40268456375838924,
          0.44966442953020136,
          0.429042904290429,
          0.40476190476190477,
          0.4503311258278146
        ],
        "19": [
          0.5906040268456376,
          0.62751677852349,
          0.5973597359735974,
          0.5986394557823129,
          0.6026490066225165
        ],
        "20": [
          0.6040268456375839,
          0.5469798657718121,
          0.5412541254125413,
          0.6394557823129252,
          0.5794701986754967
        ],
        "21": [
          0.62751677852349,
          0.5973154362416108,
          0.594059405940594,
          0.5884353741496599,
          0.652317880794702
        ],
        "22": [
          0.6644295302013423,
          0.6711409395973155,
          0.5445544554455446,
          0.608843537414966,
          0.6854304635761589
        ],
        "23": [
          0.5771812080536913,
          0.5838926174496645,
          0.6237623762376238,
          0.6360544217687075,
          0.5629139072847682
        ],
        "24": [
          0.6375838926174496,
          0.5973154362416108,
          0.6204620462046204,
          0.6224489795918368,
          0.652317880794702
        ],
        "25": [
          0.7315436241610739,
          0.6644295302013423,
          0.6270627062706271,
          0.6530612244897959,
          0.6357615894039735
        ],
        "26": [
          0.6208053691275168,
          0.6778523489932886,
          0.6501650165016502,
          0.6496598639455783,
          0.6158940397350994
        ],
        "27": [
          0.7080536912751678,
          0.6543624161073825,
          0.7326732673267327,
          0.6496598639455783,
          0.6158940397350994
        ],
        "28": [
          0.6409395973154363,
          0.7080536912751678,
          0.5313531353135313,
          0.6394557823129252,
          0.6324503311258278
        ]
      },
      "best_layer_indices_reps": [
        25,
        28,
        27,
        25,
        22
      ],
      "best_layer_accuracies_reps": [
        0.7315436241610739,
        0.7080536912751678,
        0.7326732673267327,
        0.6530612244897959,
        0.6854304635761589
      ],
      "best_layer_reports_reps": [
        "              precision    recall  f1-score   support\n\n           0       1.00      0.88      0.93        24\n           1       0.75      0.67      0.71        27\n           2       0.75      0.81      0.78        26\n           3       0.70      0.50      0.58        28\n           4       0.47      0.76      0.58        29\n           5       0.55      0.68      0.61        34\n           6       0.85      0.67      0.75        33\n           7       0.84      0.66      0.74        32\n           8       0.88      0.81      0.84        36\n           9       0.84      0.93      0.89        29\n\n    accuracy                           0.73       298\n   macro avg       0.76      0.73      0.74       298\nweighted avg       0.76      0.73      0.74       298\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        27\n           1       0.88      0.77      0.82        30\n           2       0.65      0.58      0.61        26\n           3       0.55      0.67      0.60        27\n           4       0.55      0.64      0.59        28\n           5       0.68      0.43      0.53        30\n           6       0.74      0.71      0.72        35\n           7       0.52      0.74      0.61        31\n           8       0.75      0.82      0.78        33\n           9       0.96      0.71      0.81        31\n\n    accuracy                           0.71       298\n   macro avg       0.73      0.71      0.71       298\nweighted avg       0.73      0.71      0.71       298\n",
        "              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98        25\n           1       0.89      0.65      0.76        26\n           2       0.81      0.76      0.79        29\n           3       0.59      0.90      0.71        29\n           4       0.63      0.69      0.66        32\n           5       0.81      0.57      0.67        30\n           6       0.79      0.63      0.70        35\n           7       0.80      0.62      0.70        32\n           8       0.60      0.74      0.67        35\n           9       0.71      0.83      0.77        30\n\n    accuracy                           0.73       303\n   macro avg       0.76      0.74      0.74       303\nweighted avg       0.75      0.73      0.73       303\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      0.96      0.98        25\n           1       0.66      0.74      0.70        31\n           2       0.59      0.65      0.62        26\n           3       0.35      0.23      0.28        26\n           4       0.84      0.52      0.64        31\n           5       0.53      0.55      0.54        29\n           6       0.48      0.80      0.60        30\n           7       0.56      0.74      0.63        27\n           8       0.78      0.76      0.77        37\n           9       1.00      0.56      0.72        32\n\n    accuracy                           0.65       294\n   macro avg       0.68      0.65      0.65       294\nweighted avg       0.69      0.65      0.65       294\n",
        "              precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96        27\n           1       0.74      0.65      0.69        26\n           2       0.68      0.50      0.58        26\n           3       0.59      0.54      0.57        24\n           4       0.55      0.79      0.65        33\n           5       0.52      0.48      0.50        31\n           6       0.69      0.53      0.60        34\n           7       0.73      0.77      0.75        35\n           8       0.76      0.71      0.74        35\n           9       0.69      0.87      0.77        31\n\n    accuracy                           0.69       302\n   macro avg       0.69      0.68      0.68       302\nweighted avg       0.69      0.69      0.68       302\n"
      ]
    },
    "700-709": {
      "target_sums": [
        700,
        701,
        702,
        703,
        704,
        705,
        706,
        707,
        708,
        709
      ],
      "n_classes": 10,
      "generation_accuracies_reps": [
        0.207,
        0.1975,
        0.20775,
        0.2025,
        0.20675
      ],
      "original_sample_counts_reps": [
        4000,
        4000,
        4000,
        4000,
        4000
      ],
      "filtered_sample_counts_reps": [
        828,
        790,
        831,
        810,
        827
      ],
      "probe_accuracies_per_layer_reps": {
        "1": [
          0.14457831325301204,
          0.10759493670886076,
          0.1317365269461078,
          0.12345679012345678,
          0.12048192771084337
        ],
        "2": [
          0.09036144578313253,
          0.12025316455696203,
          0.1377245508982036,
          0.12962962962962962,
          0.12650602409638553
        ],
        "3": [
          0.12650602409638553,
          0.14556962025316456,
          0.1437125748502994,
          0.1728395061728395,
          0.12048192771084337
        ],
        "4": [
          0.12650602409638553,
          0.15822784810126583,
          0.1317365269461078,
          0.12962962962962962,
          0.13855421686746988
        ],
        "5": [
          0.13855421686746988,
          0.13924050632911392,
          0.12574850299401197,
          0.11728395061728394,
          0.1746987951807229
        ],
        "6": [
          0.1566265060240964,
          0.12658227848101267,
          0.1497005988023952,
          0.17901234567901234,
          0.1566265060240964
        ],
        "7": [
          0.14457831325301204,
          0.1518987341772152,
          0.09580838323353294,
          0.1419753086419753,
          0.13253012048192772
        ],
        "8": [
          0.12048192771084337,
          0.14556962025316456,
          0.11377245508982035,
          0.14814814814814814,
          0.15060240963855423
        ],
        "9": [
          0.14457831325301204,
          0.20253164556962025,
          0.15568862275449102,
          0.13580246913580246,
          0.20481927710843373
        ],
        "10": [
          0.13253012048192772,
          0.20253164556962025,
          0.20359281437125748,
          0.17901234567901234,
          0.2469879518072289
        ],
        "11": [
          0.21686746987951808,
          0.20253164556962025,
          0.23353293413173654,
          0.30246913580246915,
          0.3373493975903614
        ],
        "12": [
          0.15060240963855423,
          0.189873417721519,
          0.18562874251497005,
          0.22839506172839505,
          0.19879518072289157
        ],
        "13": [
          0.18674698795180722,
          0.25316455696202533,
          0.19760479041916168,
          0.2654320987654321,
          0.25301204819277107
        ],
        "14": [
          0.23493975903614459,
          0.2848101265822785,
          0.2155688622754491,
          0.22839506172839505,
          0.2891566265060241
        ],
        "15": [
          0.21686746987951808,
          0.2974683544303797,
          0.2634730538922156,
          0.2345679012345679,
          0.2710843373493976
        ],
        "16": [
          0.2891566265060241,
          0.1962025316455696,
          0.2275449101796407,
          0.17901234567901234,
          0.29518072289156627
        ],
        "17": [
          0.29518072289156627,
          0.2911392405063291,
          0.23952095808383234,
          0.3333333333333333,
          0.39759036144578314
        ],
        "18": [
          0.3433734939759036,
          0.3987341772151899,
          0.31137724550898205,
          0.2839506172839506,
          0.3132530120481928
        ],
        "19": [
          0.5,
          0.5063291139240507,
          0.5269461077844312,
          0.4691358024691358,
          0.6024096385542169
        ],
        "20": [
          0.46987951807228917,
          0.5,
          0.4550898203592814,
          0.4876543209876543,
          0.5060240963855421
        ],
        "21": [
          0.5,
          0.47468354430379744,
          0.5089820359281437,
          0.4876543209876543,
          0.4759036144578313
        ],
        "22": [
          0.46987951807228917,
          0.5443037974683544,
          0.5808383233532934,
          0.4074074074074074,
          0.5963855421686747
        ],
        "23": [
          0.4759036144578313,
          0.5822784810126582,
          0.47904191616766467,
          0.4506172839506173,
          0.46987951807228917
        ],
        "24": [
          0.5662650602409639,
          0.5379746835443038,
          0.5269461077844312,
          0.5555555555555556,
          0.5843373493975904
        ],
        "25": [
          0.4879518072289157,
          0.5316455696202531,
          0.592814371257485,
          0.5370370370370371,
          0.5421686746987951
        ],
        "26": [
          0.5542168674698795,
          0.6139240506329114,
          0.562874251497006,
          0.49382716049382713,
          0.5843373493975904
        ],
        "27": [
          0.5180722891566265,
          0.5443037974683544,
          0.6047904191616766,
          0.5370370370370371,
          0.6204819277108434
        ],
        "28": [
          0.5301204819277109,
          0.5759493670886076,
          0.5568862275449101,
          0.48148148148148145,
          0.5662650602409639
        ]
      },
      "best_layer_indices_reps": [
        24,
        26,
        27,
        24,
        27
      ],
      "best_layer_accuracies_reps": [
        0.5662650602409639,
        0.6139240506329114,
        0.6047904191616766,
        0.5555555555555556,
        0.6204819277108434
      ],
      "best_layer_reports_reps": [
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       0.45      0.56      0.50         9\n           2       0.47      0.60      0.53        15\n           3       0.64      0.50      0.56        14\n           4       0.58      0.65      0.61        17\n           5       0.43      0.17      0.24        18\n           6       0.54      0.39      0.45        18\n           7       0.58      0.61      0.60        23\n           8       0.44      0.70      0.54        20\n           9       0.70      0.64      0.67        22\n\n    accuracy                           0.57       166\n   macro avg       0.58      0.58      0.57       166\nweighted avg       0.57      0.57      0.56       166\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      0.86      0.92         7\n           1       1.00      0.10      0.18        10\n           2       0.61      0.79      0.69        14\n           3       0.60      0.60      0.60        10\n           4       0.71      0.71      0.71        17\n           5       0.52      0.72      0.60        18\n           6       0.53      0.53      0.53        19\n           7       0.54      0.68      0.60        22\n           8       0.50      0.44      0.47        18\n           9       0.83      0.65      0.73        23\n\n    accuracy                           0.61       158\n   macro avg       0.68      0.61      0.60       158\nweighted avg       0.65      0.61      0.60       158\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      0.83      0.91         6\n           1       0.50      0.30      0.38        10\n           2       0.50      0.75      0.60        16\n           3       0.78      0.44      0.56        16\n           4       0.90      0.56      0.69        16\n           5       0.35      0.72      0.47        18\n           6       0.53      0.77      0.63        22\n           7       0.71      0.45      0.56        22\n           8       0.78      0.37      0.50        19\n           9       0.86      0.82      0.84        22\n\n    accuracy                           0.60       167\n   macro avg       0.69      0.60      0.61       167\nweighted avg       0.68      0.60      0.61       167\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         9\n           1       0.32      0.91      0.48        11\n           2       0.50      0.08      0.13        13\n           3       0.43      0.50      0.46        12\n           4       0.70      0.47      0.56        15\n           5       0.58      0.55      0.56        20\n           6       0.47      0.37      0.41        19\n           7       0.77      0.48      0.59        21\n           8       0.50      0.86      0.63        21\n           9       0.85      0.52      0.65        21\n\n    accuracy                           0.56       162\n   macro avg       0.61      0.57      0.55       162\nweighted avg       0.61      0.56      0.54       162\n",
        "              precision    recall  f1-score   support\n\n           0       0.73      0.89      0.80         9\n           1       0.58      0.58      0.58        12\n           2       0.45      1.00      0.62        13\n           3       0.67      0.33      0.44        12\n           4       0.55      0.38      0.44        16\n           5       0.47      0.70      0.56        20\n           6       0.71      0.60      0.65        20\n           7       0.61      0.61      0.61        23\n           8       1.00      0.40      0.57        20\n           9       0.89      0.81      0.85        21\n\n    accuracy                           0.62       166\n   macro avg       0.66      0.63      0.61       166\nweighted avg       0.68      0.62      0.62       166\n"
      ]
    },
    "800-809": {
      "target_sums": [
        800,
        801,
        802,
        803,
        804,
        805,
        806,
        807,
        808,
        809
      ],
      "n_classes": 10,
      "generation_accuracies_reps": [
        0.2065,
        0.1935,
        0.19225,
        0.20975,
        0.18875
      ],
      "original_sample_counts_reps": [
        4000,
        4000,
        4000,
        4000,
        4000
      ],
      "filtered_sample_counts_reps": [
        826,
        774,
        769,
        839,
        755
      ],
      "probe_accuracies_per_layer_reps": {
        "1": [
          0.12650602409638553,
          0.12258064516129032,
          0.16233766233766234,
          0.13690476190476192,
          0.1390728476821192
        ],
        "2": [
          0.14457831325301204,
          0.11612903225806452,
          0.12987012987012986,
          0.11904761904761904,
          0.11920529801324503
        ],
        "3": [
          0.0963855421686747,
          0.12258064516129032,
          0.18831168831168832,
          0.125,
          0.11258278145695365
        ],
        "4": [
          0.18674698795180722,
          0.13548387096774195,
          0.16883116883116883,
          0.125,
          0.13245033112582782
        ],
        "5": [
          0.14457831325301204,
          0.12903225806451613,
          0.16883116883116883,
          0.13690476190476192,
          0.1390728476821192
        ],
        "6": [
          0.18674698795180722,
          0.17419354838709677,
          0.18831168831168832,
          0.13095238095238096,
          0.152317880794702
        ],
        "7": [
          0.21686746987951808,
          0.15483870967741936,
          0.12987012987012986,
          0.09523809523809523,
          0.16556291390728478
        ],
        "8": [
          0.18674698795180722,
          0.14193548387096774,
          0.2012987012987013,
          0.14285714285714285,
          0.18543046357615894
        ],
        "9": [
          0.16265060240963855,
          0.16129032258064516,
          0.16233766233766234,
          0.15476190476190477,
          0.19205298013245034
        ],
        "10": [
          0.2710843373493976,
          0.15483870967741936,
          0.15584415584415584,
          0.20238095238095238,
          0.25165562913907286
        ],
        "11": [
          0.22289156626506024,
          0.1935483870967742,
          0.16233766233766234,
          0.17261904761904762,
          0.12582781456953643
        ],
        "12": [
          0.15060240963855423,
          0.16774193548387098,
          0.23376623376623376,
          0.23809523809523808,
          0.2251655629139073
        ],
        "13": [
          0.2469879518072289,
          0.25806451612903225,
          0.14285714285714285,
          0.20238095238095238,
          0.19205298013245034
        ],
        "14": [
          0.3072289156626506,
          0.22580645161290322,
          0.3051948051948052,
          0.22023809523809523,
          0.2052980132450331
        ],
        "15": [
          0.23493975903614459,
          0.2709677419354839,
          0.2727272727272727,
          0.20833333333333334,
          0.24503311258278146
        ],
        "16": [
          0.24096385542168675,
          0.27741935483870966,
          0.21428571428571427,
          0.27976190476190477,
          0.26490066225165565
        ],
        "17": [
          0.3313253012048193,
          0.27741935483870966,
          0.3181818181818182,
          0.34523809523809523,
          0.2847682119205298
        ],
        "18": [
          0.3313253012048193,
          0.3225806451612903,
          0.35064935064935066,
          0.3630952380952381,
          0.3509933774834437
        ],
        "19": [
          0.5662650602409639,
          0.5548387096774193,
          0.5064935064935064,
          0.5178571428571429,
          0.5033112582781457
        ],
        "20": [
          0.5602409638554217,
          0.4774193548387097,
          0.5974025974025974,
          0.4226190476190476,
          0.47019867549668876
        ],
        "21": [
          0.5060240963855421,
          0.5032258064516129,
          0.5324675324675324,
          0.5,
          0.3973509933774834
        ],
        "22": [
          0.608433734939759,
          0.4838709677419355,
          0.512987012987013,
          0.5714285714285714,
          0.5099337748344371
        ],
        "23": [
          0.5662650602409639,
          0.567741935483871,
          0.5974025974025974,
          0.5238095238095238,
          0.5165562913907285
        ],
        "24": [
          0.5903614457831325,
          0.5032258064516129,
          0.42207792207792205,
          0.5416666666666666,
          0.44370860927152317
        ],
        "25": [
          0.6325301204819277,
          0.5741935483870968,
          0.564935064935065,
          0.6011904761904762,
          0.5364238410596026
        ],
        "26": [
          0.5301204819277109,
          0.535483870967742,
          0.5584415584415584,
          0.5119047619047619,
          0.5298013245033113
        ],
        "27": [
          0.5903614457831325,
          0.5483870967741935,
          0.5714285714285714,
          0.6309523809523809,
          0.6026490066225165
        ],
        "28": [
          0.5301204819277109,
          0.4838709677419355,
          0.4675324675324675,
          0.5357142857142857,
          0.44370860927152317
        ]
      },
      "best_layer_indices_reps": [
        25,
        25,
        20,
        27,
        27
      ],
      "best_layer_accuracies_reps": [
        0.6325301204819277,
        0.5741935483870968,
        0.5974025974025974,
        0.6309523809523809,
        0.6026490066225165
      ],
      "best_layer_reports_reps": [
        "              precision    recall  f1-score   support\n\n           0       1.00      0.89      0.94         9\n           1       0.75      0.82      0.78        11\n           2       0.50      0.60      0.55        15\n           3       0.50      0.50      0.50        12\n           4       0.82      0.56      0.67        25\n           5       0.46      0.58      0.51        19\n           6       0.55      0.65      0.59        17\n           7       0.64      0.33      0.44        21\n           8       0.64      0.80      0.71        20\n           9       0.74      0.82      0.78        17\n\n    accuracy                           0.63       166\n   macro avg       0.66      0.65      0.65       166\nweighted avg       0.65      0.63      0.63       166\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      0.89      0.94         9\n           1       0.62      0.50      0.56        10\n           2       0.39      0.50      0.44        14\n           3       0.50      0.36      0.42        14\n           4       0.43      0.38      0.40        16\n           5       0.43      0.35      0.39        17\n           6       0.47      0.47      0.47        17\n           7       0.62      0.53      0.57        19\n           8       0.64      0.90      0.75        20\n           9       0.73      0.84      0.78        19\n\n    accuracy                           0.57       155\n   macro avg       0.58      0.57      0.57       155\nweighted avg       0.57      0.57      0.57       155\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      0.89      0.94         9\n           1       1.00      0.67      0.80         9\n           2       0.44      0.36      0.40        11\n           3       0.75      0.21      0.33        14\n           4       0.45      0.68      0.54        19\n           5       0.83      0.29      0.43        17\n           6       0.45      0.33      0.38        15\n           7       0.42      0.90      0.57        20\n           8       0.73      0.73      0.73        22\n           9       0.88      0.78      0.82        18\n\n    accuracy                           0.60       154\n   macro avg       0.70      0.59      0.60       154\nweighted avg       0.67      0.60      0.59       154\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      0.80      0.89        10\n           1       0.78      0.70      0.74        10\n           2       0.85      0.73      0.79        15\n           3       0.85      0.65      0.73        17\n           4       0.68      0.65      0.67        23\n           5       0.62      0.26      0.37        19\n           6       0.46      0.69      0.55        16\n           7       0.39      0.57      0.46        21\n           8       0.71      0.60      0.65        20\n           9       0.61      0.82      0.70        17\n\n    accuracy                           0.63       168\n   macro avg       0.69      0.65      0.65       168\nweighted avg       0.67      0.63      0.63       168\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      0.91      0.95        11\n           1       0.60      0.30      0.40        10\n           2       0.80      0.31      0.44        13\n           3       0.80      0.62      0.70        13\n           4       0.59      0.72      0.65        18\n           5       0.62      0.59      0.61        17\n           6       0.50      0.33      0.40        15\n           7       0.56      0.71      0.62        21\n           8       0.39      0.81      0.53        16\n           9       0.77      0.59      0.67        17\n\n    accuracy                           0.60       151\n   macro avg       0.66      0.59      0.60       151\nweighted avg       0.65      0.60      0.60       151\n"
      ]
    },
    "900-909": {
      "target_sums": [
        900,
        901,
        902,
        903,
        904,
        905,
        906,
        907,
        908,
        909
      ],
      "n_classes": 10,
      "generation_accuracies_reps": [
        0.348,
        0.34825,
        0.35075,
        0.3475,
        0.35075
      ],
      "original_sample_counts_reps": [
        4000,
        4000,
        4000,
        4000,
        4000
      ],
      "filtered_sample_counts_reps": [
        1392,
        1393,
        1403,
        1390,
        1403
      ],
      "probe_accuracies_per_layer_reps": {
        "1": [
          0.11469534050179211,
          0.11469534050179211,
          0.12455516014234876,
          0.10071942446043165,
          0.099644128113879
        ],
        "2": [
          0.12544802867383512,
          0.1039426523297491,
          0.12099644128113879,
          0.1079136690647482,
          0.12455516014234876
        ],
        "3": [
          0.13261648745519714,
          0.13620071684587814,
          0.12811387900355872,
          0.1079136690647482,
          0.10676156583629894
        ],
        "4": [
          0.1039426523297491,
          0.12544802867383512,
          0.12099644128113879,
          0.10071942446043165,
          0.10676156583629894
        ],
        "5": [
          0.17562724014336917,
          0.14695340501792115,
          0.1708185053380783,
          0.1223021582733813,
          0.12811387900355872
        ],
        "6": [
          0.1039426523297491,
          0.16129032258064516,
          0.11387900355871886,
          0.1510791366906475,
          0.12455516014234876
        ],
        "7": [
          0.13978494623655913,
          0.11469534050179211,
          0.13167259786476868,
          0.1474820143884892,
          0.11743772241992882
        ],
        "8": [
          0.12544802867383512,
          0.10752688172043011,
          0.1494661921708185,
          0.12949640287769784,
          0.11743772241992882
        ],
        "9": [
          0.10752688172043011,
          0.1863799283154122,
          0.14590747330960854,
          0.14028776978417265,
          0.1601423487544484
        ],
        "10": [
          0.24372759856630824,
          0.25448028673835127,
          0.23843416370106763,
          0.2805755395683453,
          0.21708185053380782
        ],
        "11": [
          0.22939068100358423,
          0.1827956989247312,
          0.18505338078291814,
          0.21942446043165467,
          0.2277580071174377
        ],
        "12": [
          0.24014336917562723,
          0.25089605734767023,
          0.2277580071174377,
          0.2302158273381295,
          0.2206405693950178
        ],
        "13": [
          0.22939068100358423,
          0.27598566308243727,
          0.21352313167259787,
          0.24100719424460432,
          0.2313167259786477
        ],
        "14": [
          0.23297491039426524,
          0.21863799283154123,
          0.25622775800711745,
          0.2733812949640288,
          0.22419928825622776
        ],
        "15": [
          0.23655913978494625,
          0.23297491039426524,
          0.29537366548042704,
          0.20863309352517986,
          0.23487544483985764
        ],
        "16": [
          0.30824372759856633,
          0.35125448028673834,
          0.2704626334519573,
          0.2733812949640288,
          0.21352313167259787
        ],
        "17": [
          0.4014336917562724,
          0.3727598566308244,
          0.3167259786476868,
          0.3597122302158273,
          0.3594306049822064
        ],
        "18": [
          0.3906810035842294,
          0.34050179211469533,
          0.3665480427046263,
          0.38489208633093525,
          0.3914590747330961
        ],
        "19": [
          0.6057347670250897,
          0.5555555555555556,
          0.6370106761565836,
          0.5503597122302158,
          0.5444839857651246
        ],
        "20": [
          0.5734767025089605,
          0.5555555555555556,
          0.5693950177935944,
          0.5467625899280576,
          0.5587188612099644
        ],
        "21": [
          0.5734767025089605,
          0.6272401433691757,
          0.5302491103202847,
          0.5179856115107914,
          0.5871886120996441
        ],
        "22": [
          0.5949820788530465,
          0.5125448028673835,
          0.5836298932384342,
          0.6151079136690647,
          0.6405693950177936
        ],
        "23": [
          0.5770609318996416,
          0.5842293906810035,
          0.6156583629893239,
          0.5323741007194245,
          0.4875444839857651
        ],
        "24": [
          0.5268817204301075,
          0.5770609318996416,
          0.5551601423487544,
          0.539568345323741,
          0.5266903914590747
        ],
        "25": [
          0.5913978494623656,
          0.5842293906810035,
          0.5480427046263345,
          0.6079136690647482,
          0.505338078291815
        ],
        "26": [
          0.6487455197132617,
          0.6057347670250897,
          0.5693950177935944,
          0.5107913669064749,
          0.4875444839857651
        ],
        "27": [
          0.6093189964157706,
          0.5268817204301075,
          0.5836298932384342,
          0.5611510791366906,
          0.5444839857651246
        ],
        "28": [
          0.5555555555555556,
          0.5376344086021505,
          0.6120996441281139,
          0.564748201438849,
          0.49110320284697506
        ]
      },
      "best_layer_indices_reps": [
        26,
        21,
        19,
        22,
        22
      ],
      "best_layer_accuracies_reps": [
        0.6487455197132617,
        0.6272401433691757,
        0.6370106761565836,
        0.6151079136690647,
        0.6405693950177936
      ],
      "best_layer_reports_reps": [
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        24\n           1       0.79      0.83      0.81        23\n           2       0.67      0.56      0.61        25\n           3       0.93      0.43      0.59        30\n           4       0.43      0.26      0.32        23\n           5       0.54      0.61      0.57        23\n           6       0.44      0.88      0.59        32\n           7       0.79      0.50      0.61        30\n           8       0.51      0.60      0.55        35\n           9       0.82      0.79      0.81        34\n\n    accuracy                           0.65       279\n   macro avg       0.69      0.65      0.65       279\nweighted avg       0.69      0.65      0.65       279\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        20\n           1       0.57      0.40      0.47        20\n           2       1.00      0.30      0.46        27\n           3       0.52      0.43      0.47        30\n           4       0.70      0.62      0.65        26\n           5       0.41      0.76      0.54        25\n           6       0.46      0.75      0.57        32\n           7       0.66      0.66      0.66        32\n           8       0.71      0.68      0.69        40\n           9       0.90      0.70      0.79        27\n\n    accuracy                           0.63       279\n   macro avg       0.69      0.63      0.63       279\nweighted avg       0.68      0.63      0.63       279\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        21\n           1       0.40      0.92      0.56        24\n           2       0.65      0.50      0.57        26\n           3       0.67      0.32      0.43        31\n           4       0.35      0.38      0.36        21\n           5       0.64      0.48      0.55        29\n           6       0.60      0.60      0.60        30\n           7       0.76      0.67      0.71        33\n           8       0.67      0.74      0.70        35\n           9       0.93      0.81      0.86        31\n\n    accuracy                           0.64       281\n   macro avg       0.67      0.64      0.63       281\nweighted avg       0.67      0.64      0.64       281\n",
        "              precision    recall  f1-score   support\n\n           0       0.93      1.00      0.96        25\n           1       0.45      0.74      0.56        19\n           2       0.53      0.87      0.66        23\n           3       0.59      0.59      0.59        27\n           4       0.45      0.40      0.43        25\n           5       0.50      0.38      0.43        29\n           6       0.60      0.10      0.17        30\n           7       1.00      0.47      0.64        30\n           8       0.48      0.78      0.60        36\n           9       0.88      0.88      0.88        34\n\n    accuracy                           0.62       278\n   macro avg       0.64      0.62      0.59       278\nweighted avg       0.65      0.62      0.59       278\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        25\n           1       0.91      0.43      0.59        23\n           2       0.47      0.75      0.58        28\n           3       0.47      0.69      0.56        32\n           4       0.35      0.32      0.33        22\n           5       0.59      0.59      0.59        29\n           6       0.69      0.64      0.67        28\n           7       0.79      0.58      0.67        33\n           8       0.68      0.53      0.60        32\n           9       0.83      0.83      0.83        29\n\n    accuracy                           0.64       281\n   macro avg       0.68      0.64      0.64       281\nweighted avg       0.68      0.64      0.64       281\n"
      ]
    }
  },
  "best_layer_mode_per_range": {
    "500-509": 27,
    "600-609": 25,
    "700-709": 24,
    "800-809": 25,
    "900-909": 22
  }
}