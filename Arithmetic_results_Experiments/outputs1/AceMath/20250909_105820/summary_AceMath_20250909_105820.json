{
  "model": "/root/autodl-tmp/AceMath",
  "model_short": "AceMath",
  "timestamp": "20250909_105820",
  "device": "cuda:0",
  "hyper_params": {
    "MODEL_NAMES": [
      "/root/autodl-tmp/llama",
      "/root/autodl-tmp/Mistral",
      "/root/autodl-tmp/Qwen2.5-Math-7B",
      "/root/autodl-tmp/AceMath",
      "/root/autodl-tmp/Qwen2.5-7B-Instruct"
    ],
    "N_REPETITIONS": 5,
    "BASE_SEED": 42,
    "PROBE_TYPE": "linear",
    "PROBE_MLP_HIDDEN_DIM": 4096,
    "N_PROBE_EPOCHS": 5,
    "PROBE_LR": 0.001,
    "PROBE_BATCH_SIZE": 64,
    "TEST_SPLIT_RATIO": 0.2,
    "GENERATION_BATCH_SIZE": 500,
    "GEN_MAX_NEW_TOKENS": 3,
    "GEN_DO_SAMPLE": false,
    "TOK_MAX_LENGTH": 60,
    "TOK_PADDING_SIDE": "left",
    "SUM_RANGES_CONFIG": [
      {
        "label": "500-509",
        "start": 500,
        "count": 10
      },
      {
        "label": "600-609",
        "start": 600,
        "count": 10
      },
      {
        "label": "700-709",
        "start": 700,
        "count": 10
      },
      {
        "label": "800-809",
        "start": 800,
        "count": 10
      },
      {
        "label": "900-909",
        "start": 900,
        "count": 10
      }
    ],
    "N_SAMPLES_PER_SUM": 400,
    "MIN_SAMPLES_PER_CLASS_FOR_PROBING": 5,
    "MIN_ADDEND_VAL": 100,
    "A_BOUND_LOW_FRAC": 0.25,
    "A_BOUND_HIGH_FRAC": 0.75,
    "MAX_ATTEMPTS_MULTIPLIER": 20,
    "ACTIVATIONS_BATCH_SIZE": 256,
    "LOG_TO_CONSOLE": false,
    "TQDM_DISABLED": true,
    "SUPPRESS_WARNINGS": true
  },
  "probe_type": "linear",
  "probe_epochs": 5,
  "probe_lr": 0.001,
  "probe_batch_size": 64,
  "generation_batch_size": 500,
  "sum_ranges_config": [
    {
      "label": "500-509",
      "start": 500,
      "count": 10
    },
    {
      "label": "600-609",
      "start": 600,
      "count": 10
    },
    {
      "label": "700-709",
      "start": 700,
      "count": 10
    },
    {
      "label": "800-809",
      "start": 800,
      "count": 10
    },
    {
      "label": "900-909",
      "start": 900,
      "count": 10
    }
  ],
  "n_samples_per_sum": 400,
  "test_split_ratio": 0.2,
  "layers_to_probe": [
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18,
    19,
    20,
    21,
    22,
    23,
    24,
    25,
    26,
    27,
    28
  ],
  "logical_num_layers": 28,
  "hidden_states_tuple_len": 29,
  "results": {
    "500-509": {
      "target_sums": [
        500,
        501,
        502,
        503,
        504,
        505,
        506,
        507,
        508,
        509
      ],
      "n_classes": 10,
      "generation_accuracies_reps": [
        0.65075,
        0.647,
        0.64875,
        0.65775,
        0.66375
      ],
      "original_sample_counts_reps": [
        4000,
        4000,
        4000,
        4000,
        4000
      ],
      "filtered_sample_counts_reps": [
        2603,
        2588,
        2595,
        2631,
        2655
      ],
      "probe_accuracies_per_layer_reps": {
        "1": [
          0.11324376199616124,
          0.1138996138996139,
          0.1233140655105973,
          0.11005692599620494,
          0.09981167608286252
        ],
        "2": [
          0.11516314779270634,
          0.1274131274131274,
          0.13102119460500963,
          0.10246679316888045,
          0.10922787193973635
        ],
        "3": [
          0.13051823416506717,
          0.15444015444015444,
          0.11560693641618497,
          0.1157495256166983,
          0.12617702448210924
        ],
        "4": [
          0.1017274472168906,
          0.1138996138996139,
          0.1599229287090559,
          0.1347248576850095,
          0.10922787193973635
        ],
        "5": [
          0.16506717850287908,
          0.12162162162162163,
          0.14836223506743737,
          0.11385199240986717,
          0.1544256120527307
        ],
        "6": [
          0.16314779270633398,
          0.15444015444015444,
          0.16377649325626203,
          0.12903225806451613,
          0.11487758945386065
        ],
        "7": [
          0.1401151631477927,
          0.12355212355212356,
          0.18882466281310212,
          0.1366223908918406,
          0.1431261770244821
        ],
        "8": [
          0.1727447216890595,
          0.1776061776061776,
          0.2023121387283237,
          0.1442125237191651,
          0.18832391713747645
        ],
        "9": [
          0.1746641074856046,
          0.12548262548262548,
          0.14450867052023122,
          0.16698292220113853,
          0.1431261770244821
        ],
        "10": [
          0.30518234165067176,
          0.24324324324324326,
          0.27167630057803466,
          0.2903225806451613,
          0.23163841807909605
        ],
        "11": [
          0.29750479846449135,
          0.2548262548262548,
          0.3468208092485549,
          0.3415559772296015,
          0.2617702448210923
        ],
        "12": [
          0.32437619961612285,
          0.25096525096525096,
          0.22350674373795762,
          0.2884250474383302,
          0.2617702448210923
        ],
        "13": [
          0.26103646833013433,
          0.30115830115830117,
          0.2813102119460501,
          0.2713472485768501,
          0.2730696798493409
        ],
        "14": [
          0.3666026871401152,
          0.22007722007722008,
          0.23314065510597304,
          0.3396584440227704,
          0.2674199623352166
        ],
        "15": [
          0.30134357005758156,
          0.23552123552123552,
          0.2813102119460501,
          0.25806451612903225,
          0.23540489642184556
        ],
        "16": [
          0.32053742802303264,
          0.23745173745173745,
          0.32947976878612717,
          0.2846299810246679,
          0.1902071563088512
        ],
        "17": [
          0.4952015355086372,
          0.4575289575289575,
          0.36801541425818884,
          0.4857685009487666,
          0.4256120527306968
        ],
        "18": [
          0.4817658349328215,
          0.5,
          0.51252408477842,
          0.4838709677419355,
          0.4783427495291902
        ],
        "19": [
          0.5969289827255279,
          0.6254826254826255,
          0.628131021194605,
          0.5882352941176471,
          0.5310734463276836
        ],
        "20": [
          0.6257197696737045,
          0.6525096525096525,
          0.6628131021194605,
          0.681214421252372,
          0.7099811676082862
        ],
        "21": [
          0.6737044145873321,
          0.61003861003861,
          0.6011560693641619,
          0.5996204933586338,
          0.4858757062146893
        ],
        "22": [
          0.6026871401151631,
          0.7027027027027027,
          0.5761078998073218,
          0.7039848197343453,
          0.6760828625235404
        ],
        "23": [
          0.6372360844529751,
          0.6486486486486487,
          0.653179190751445,
          0.5635673624288425,
          0.5404896421845574
        ],
        "24": [
          0.6199616122840691,
          0.6988416988416989,
          0.7129094412331407,
          0.6850094876660342,
          0.6290018832391714
        ],
        "25": [
          0.6602687140115163,
          0.7142857142857143,
          0.6069364161849711,
          0.6394686907020873,
          0.6591337099811676
        ],
        "26": [
          0.7408829174664108,
          0.6428571428571429,
          0.6801541425818882,
          0.6470588235294118,
          0.6629001883239172
        ],
        "27": [
          0.6737044145873321,
          0.6351351351351351,
          0.6146435452793835,
          0.635673624288425,
          0.6421845574387948
        ],
        "28": [
          0.6660268714011516,
          0.6872586872586872,
          0.5684007707129094,
          0.5977229601518027,
          0.6629001883239172
        ]
      },
      "best_layer_indices_reps": [
        26,
        25,
        24,
        22,
        20
      ],
      "best_layer_accuracies_reps": [
        0.7408829174664108,
        0.7142857142857143,
        0.7129094412331407,
        0.7039848197343453,
        0.7099811676082862
      ],
      "best_layer_reports_reps": [
        "              precision    recall  f1-score   support\n\n           0       1.00      0.98      0.99        54\n           1       0.83      0.54      0.66        35\n           2       0.81      0.63      0.71        46\n           3       0.62      0.79      0.70        48\n           4       0.73      0.80      0.76        46\n           5       0.75      0.59      0.66        56\n           6       0.68      0.51      0.58        55\n           7       0.56      0.77      0.65        57\n           8       0.74      0.92      0.82        64\n           9       0.85      0.77      0.81        60\n\n    accuracy                           0.74       521\n   macro avg       0.76      0.73      0.73       521\nweighted avg       0.75      0.74      0.74       521\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        57\n           1       0.73      0.61      0.67        36\n           2       0.81      0.88      0.84        48\n           3       0.68      0.67      0.67        45\n           4       0.95      0.38      0.54        50\n           5       0.56      0.58      0.57        50\n           6       0.41      0.87      0.55        55\n           7       0.71      0.72      0.72        54\n           8       0.90      0.44      0.59        62\n           9       0.95      0.93      0.94        61\n\n    accuracy                           0.71       518\n   macro avg       0.77      0.71      0.71       518\nweighted avg       0.78      0.71      0.71       518\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        53\n           1       0.60      0.94      0.74        34\n           2       0.82      0.85      0.84        48\n           3       0.72      0.43      0.54        49\n           4       0.91      0.59      0.71        51\n           5       0.57      0.55      0.56        53\n           6       0.64      0.57      0.60        56\n           7       0.92      0.44      0.59        55\n           8       0.57      0.84      0.68        61\n           9       0.68      0.97      0.80        59\n\n    accuracy                           0.71       519\n   macro avg       0.74      0.72      0.71       519\nweighted avg       0.74      0.71      0.70       519\n",
        "              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99        55\n           1       0.88      0.60      0.71        35\n           2       0.89      0.49      0.63        51\n           3       0.77      0.42      0.54        48\n           4       0.61      0.80      0.69        54\n           5       0.55      0.82      0.66        56\n           6       0.42      0.76      0.54        55\n           7       0.73      0.58      0.65        55\n           8       0.97      0.49      0.65        59\n           9       0.88      0.98      0.93        59\n\n    accuracy                           0.70       527\n   macro avg       0.77      0.69      0.70       527\nweighted avg       0.77      0.70      0.70       527\n",
        "              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99        57\n           1       0.59      0.86      0.70        35\n           2       0.77      0.47      0.59        51\n           3       0.68      0.43      0.53        49\n           4       0.69      0.71      0.70        52\n           5       0.63      0.77      0.69        57\n           6       0.48      0.75      0.59        55\n           7       0.80      0.61      0.69        54\n           8       0.73      0.60      0.66        63\n           9       0.90      0.90      0.90        58\n\n    accuracy                           0.71       531\n   macro avg       0.73      0.71      0.70       531\nweighted avg       0.73      0.71      0.71       531\n"
      ]
    },
    "600-609": {
      "target_sums": [
        600,
        601,
        602,
        603,
        604,
        605,
        606,
        607,
        608,
        609
      ],
      "n_classes": 10,
      "generation_accuracies_reps": [
        0.851,
        0.857,
        0.8535,
        0.85925,
        0.85375
      ],
      "original_sample_counts_reps": [
        4000,
        4000,
        4000,
        4000,
        4000
      ],
      "filtered_sample_counts_reps": [
        3404,
        3428,
        3414,
        3437,
        3415
      ],
      "probe_accuracies_per_layer_reps": {
        "1": [
          0.12041116005873716,
          0.10787172011661808,
          0.11127379209370425,
          0.10755813953488372,
          0.09956076134699854
        ],
        "2": [
          0.11013215859030837,
          0.10787172011661808,
          0.10248901903367497,
          0.10465116279069768,
          0.09809663250366032
        ],
        "3": [
          0.11747430249632893,
          0.10058309037900874,
          0.10688140556368961,
          0.1119186046511628,
          0.10395314787701318
        ],
        "4": [
          0.09397944199706314,
          0.12682215743440234,
          0.12152269399707175,
          0.12790697674418605,
          0.1171303074670571
        ],
        "5": [
          0.1277533039647577,
          0.11224489795918367,
          0.11566617862371889,
          0.13372093023255813,
          0.1171303074670571
        ],
        "6": [
          0.11894273127753303,
          0.12536443148688048,
          0.12884333821376281,
          0.14534883720930233,
          0.13469985358711567
        ],
        "7": [
          0.13509544787077826,
          0.12973760932944606,
          0.12298682284040996,
          0.13953488372093023,
          0.12152269399707175
        ],
        "8": [
          0.15859030837004406,
          0.12973760932944606,
          0.15666178623718888,
          0.14970930232558138,
          0.12884333821376281
        ],
        "9": [
          0.1762114537444934,
          0.10641399416909621,
          0.17715959004392387,
          0.17877906976744187,
          0.15519765739385066
        ],
        "10": [
          0.3039647577092511,
          0.29591836734693877,
          0.30453879941434847,
          0.25,
          0.1903367496339678
        ],
        "11": [
          0.26725403817914833,
          0.2857142857142857,
          0.2796486090775988,
          0.2761627906976744,
          0.17715959004392387
        ],
        "12": [
          0.3201174743024963,
          0.26676384839650147,
          0.2796486090775988,
          0.24273255813953487,
          0.2664714494875549
        ],
        "13": [
          0.28634361233480177,
          0.29591836734693877,
          0.2225475841874085,
          0.3081395348837209,
          0.3118594436310395
        ],
        "14": [
          0.2966226138032305,
          0.2915451895043732,
          0.30453879941434847,
          0.30959302325581395,
          0.3162518301610542
        ],
        "15": [
          0.31277533039647576,
          0.27988338192419826,
          0.31332357247437775,
          0.32848837209302323,
          0.2796486090775988
        ],
        "16": [
          0.23641703377386197,
          0.3177842565597668,
          0.3118594436310395,
          0.2863372093023256,
          0.2591508052708638
        ],
        "17": [
          0.4170337738619677,
          0.47959183673469385,
          0.4011713030746706,
          0.39244186046511625,
          0.4670571010248902
        ],
        "18": [
          0.5741556534508077,
          0.41545189504373176,
          0.5197657393850659,
          0.43023255813953487,
          0.5636896046852123
        ],
        "19": [
          0.6431718061674009,
          0.673469387755102,
          0.6295754026354319,
          0.6380813953488372,
          0.6251830161054173
        ],
        "20": [
          0.7165932452276065,
          0.6895043731778425,
          0.6881405563689604,
          0.5959302325581395,
          0.7130307467057101
        ],
        "21": [
          0.5609397944199707,
          0.6530612244897959,
          0.6808199121522694,
          0.5508720930232558,
          0.664714494875549
        ],
        "22": [
          0.6372980910425844,
          0.6166180758017493,
          0.5797950219619327,
          0.6715116279069767,
          0.568081991215227
        ],
        "23": [
          0.618208516886931,
          0.6326530612244898,
          0.6720351390922401,
          0.6148255813953488,
          0.623718887262079
        ],
        "24": [
          0.6651982378854625,
          0.6530612244897959,
          0.6998535871156661,
          0.7107558139534884,
          0.6808199121522694
        ],
        "25": [
          0.7063142437591777,
          0.6967930029154519,
          0.6881405563689604,
          0.7616279069767442,
          0.5797950219619327
        ],
        "26": [
          0.6696035242290749,
          0.6428571428571429,
          0.5739385065885798,
          0.6831395348837209,
          0.6852122986822841
        ],
        "27": [
          0.6328928046989721,
          0.6880466472303207,
          0.6251830161054173,
          0.6627906976744186,
          0.6939970717423133
        ],
        "28": [
          0.6593245227606461,
          0.6836734693877551,
          0.6207906295754027,
          0.6497093023255814,
          0.6661786237188873
        ]
      },
      "best_layer_indices_reps": [
        20,
        25,
        24,
        25,
        20
      ],
      "best_layer_accuracies_reps": [
        0.7165932452276065,
        0.6967930029154519,
        0.6998535871156661,
        0.7616279069767442,
        0.7130307467057101
      ],
      "best_layer_reports_reps": [
        "              precision    recall  f1-score   support\n\n           0       1.00      0.99      0.99        68\n           1       0.62      0.96      0.75        55\n           2       0.57      0.89      0.70        64\n           3       0.69      0.59      0.64        64\n           4       0.65      0.75      0.69        68\n           5       1.00      0.07      0.14        69\n           6       0.60      0.79      0.68        71\n           7       0.74      0.90      0.81        70\n           8       1.00      0.31      0.47        75\n           9       0.85      0.97      0.91        77\n\n    accuracy                           0.72       681\n   macro avg       0.77      0.72      0.68       681\nweighted avg       0.78      0.72      0.68       681\n",
        "              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99        68\n           1       0.81      0.89      0.85        56\n           2       0.97      0.41      0.58        68\n           3       0.68      0.47      0.56        64\n           4       0.53      0.76      0.63        67\n           5       0.61      0.74      0.67        72\n           6       0.43      0.73      0.54        73\n           7       0.75      0.74      0.75        70\n           8       0.96      0.31      0.47        74\n           9       0.86      0.96      0.90        74\n\n    accuracy                           0.70       686\n   macro avg       0.76      0.70      0.69       686\nweighted avg       0.76      0.70      0.69       686\n",
        "              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99        67\n           1       0.72      0.68      0.70        57\n           2       0.88      0.79      0.83        66\n           3       0.48      0.55      0.51        64\n           4       0.60      0.52      0.56        69\n           5       0.88      0.29      0.44        72\n           6       0.52      0.77      0.62        71\n           7       0.55      0.86      0.67        69\n           8       0.98      0.62      0.76        73\n           9       0.81      0.92      0.86        75\n\n    accuracy                           0.70       683\n   macro avg       0.74      0.70      0.69       683\nweighted avg       0.74      0.70      0.69       683\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        68\n           1       0.84      0.87      0.86        55\n           2       0.71      0.88      0.79        68\n           3       0.62      0.71      0.66        66\n           4       0.65      0.80      0.72        70\n           5       0.78      0.58      0.66        73\n           6       0.56      0.72      0.63        71\n           7       0.80      0.70      0.74        69\n           8       0.89      0.44      0.59        72\n           9       0.95      0.95      0.95        76\n\n    accuracy                           0.76       688\n   macro avg       0.78      0.76      0.76       688\nweighted avg       0.78      0.76      0.76       688\n",
        "              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99        68\n           1       0.89      0.55      0.68        58\n           2       0.69      0.77      0.73        65\n           3       0.48      0.82      0.60        62\n           4       0.79      0.39      0.52        69\n           5       0.63      0.79      0.70        71\n           6       0.91      0.56      0.69        72\n           7       1.00      0.33      0.49        70\n           8       0.52      0.93      0.67        72\n           9       0.90      0.96      0.93        76\n\n    accuracy                           0.71       683\n   macro avg       0.78      0.71      0.70       683\nweighted avg       0.78      0.71      0.70       683\n"
      ]
    },
    "700-709": {
      "target_sums": [
        700,
        701,
        702,
        703,
        704,
        705,
        706,
        707,
        708,
        709
      ],
      "n_classes": 10,
      "generation_accuracies_reps": [
        0.51875,
        0.5215,
        0.52075,
        0.5075,
        0.529
      ],
      "original_sample_counts_reps": [
        4000,
        4000,
        4000,
        4000,
        4000
      ],
      "filtered_sample_counts_reps": [
        2075,
        2086,
        2083,
        2030,
        2116
      ],
      "probe_accuracies_per_layer_reps": {
        "1": [
          0.12530120481927712,
          0.1076555023923445,
          0.13908872901678657,
          0.14039408866995073,
          0.10849056603773585
        ],
        "2": [
          0.1108433734939759,
          0.13157894736842105,
          0.08633093525179857,
          0.18719211822660098,
          0.12264150943396226
        ],
        "3": [
          0.13734939759036144,
          0.14354066985645933,
          0.09592326139088729,
          0.14285714285714285,
          0.10849056603773585
        ],
        "4": [
          0.13975903614457832,
          0.11244019138755981,
          0.08872901678657075,
          0.10344827586206896,
          0.15566037735849056
        ],
        "5": [
          0.14698795180722893,
          0.15550239234449761,
          0.11990407673860912,
          0.15763546798029557,
          0.16037735849056603
        ],
        "6": [
          0.13734939759036144,
          0.15789473684210525,
          0.1366906474820144,
          0.1354679802955665,
          0.20754716981132076
        ],
        "7": [
          0.15903614457831325,
          0.18421052631578946,
          0.11031175059952038,
          0.13793103448275862,
          0.12971698113207547
        ],
        "8": [
          0.15421686746987953,
          0.16985645933014354,
          0.08393285371702638,
          0.1477832512315271,
          0.13679245283018868
        ],
        "9": [
          0.1710843373493976,
          0.1937799043062201,
          0.14388489208633093,
          0.20689655172413793,
          0.1957547169811321
        ],
        "10": [
          0.27951807228915665,
          0.24162679425837322,
          0.18225419664268586,
          0.27832512315270935,
          0.3278301886792453
        ],
        "11": [
          0.26506024096385544,
          0.2583732057416268,
          0.09112709832134293,
          0.229064039408867,
          0.29009433962264153
        ],
        "12": [
          0.26024096385542167,
          0.22248803827751196,
          0.23980815347721823,
          0.1921182266009852,
          0.2759433962264151
        ],
        "13": [
          0.2987951807228916,
          0.20574162679425836,
          0.18705035971223022,
          0.33004926108374383,
          0.23113207547169812
        ],
        "14": [
          0.27228915662650605,
          0.24162679425837322,
          0.23501199040767387,
          0.270935960591133,
          0.27358490566037735
        ],
        "15": [
          0.3036144578313253,
          0.2894736842105263,
          0.2637889688249401,
          0.2660098522167488,
          0.3089622641509434
        ],
        "16": [
          0.2987951807228916,
          0.284688995215311,
          0.15347721822541965,
          0.229064039408867,
          0.28537735849056606
        ],
        "17": [
          0.38072289156626504,
          0.41148325358851673,
          0.1630695443645084,
          0.3078817733990148,
          0.37264150943396224
        ],
        "18": [
          0.3542168674698795,
          0.45933014354066987,
          0.3908872901678657,
          0.4802955665024631,
          0.5471698113207547
        ],
        "19": [
          0.5493975903614458,
          0.47607655502392343,
          0.5371702637889688,
          0.5960591133004927,
          0.5990566037735849
        ],
        "20": [
          0.5879518072289157,
          0.5215311004784688,
          0.4028776978417266,
          0.5517241379310345,
          0.6297169811320755
        ],
        "21": [
          0.4771084337349398,
          0.47368421052631576,
          0.3764988009592326,
          0.5566502463054187,
          0.6061320754716981
        ],
        "22": [
          0.5301204819277109,
          0.49760765550239233,
          0.354916067146283,
          0.5541871921182266,
          0.5094339622641509
        ],
        "23": [
          0.5421686746987951,
          0.5047846889952153,
          0.4628297362110312,
          0.5566502463054187,
          0.5094339622641509
        ],
        "24": [
          0.5566265060240964,
          0.6220095693779905,
          0.4580335731414868,
          0.5517241379310345,
          0.5283018867924528
        ],
        "25": [
          0.6048192771084338,
          0.569377990430622,
          0.460431654676259,
          0.5714285714285714,
          0.6297169811320755
        ],
        "26": [
          0.5686746987951807,
          0.48086124401913877,
          0.5203836930455635,
          0.5911330049261084,
          0.5636792452830188
        ],
        "27": [
          0.6048192771084338,
          0.41148325358851673,
          0.5371702637889688,
          0.6133004926108374,
          0.5613207547169812
        ],
        "28": [
          0.5975903614457831,
          0.5047846889952153,
          0.565947242206235,
          0.5763546798029556,
          0.6202830188679245
        ]
      },
      "best_layer_indices_reps": [
        25,
        24,
        28,
        27,
        20
      ],
      "best_layer_accuracies_reps": [
        0.6048192771084338,
        0.6220095693779905,
        0.565947242206235,
        0.6133004926108374,
        0.6297169811320755
      ],
      "best_layer_reports_reps": [
        "              precision    recall  f1-score   support\n\n           0       1.00      0.97      0.98        29\n           1       0.71      0.54      0.61        28\n           2       0.57      0.79      0.66        33\n           3       0.34      0.59      0.43        37\n           4       0.53      0.63      0.57        46\n           5       0.67      0.13      0.21        47\n           6       0.71      0.22      0.33        46\n           7       0.50      0.62      0.55        42\n           8       0.61      0.74      0.67        50\n           9       0.81      0.91      0.86        57\n\n    accuracy                           0.60       415\n   macro avg       0.64      0.61      0.59       415\nweighted avg       0.64      0.60      0.58       415\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        33\n           1       0.61      0.48      0.54        29\n           2       0.60      0.60      0.60        35\n           3       0.43      0.50      0.46        36\n           4       0.56      0.57      0.57        40\n           5       0.47      0.51      0.49        49\n           6       0.83      0.11      0.19        46\n           7       0.51      0.56      0.53        41\n           8       0.59      0.86      0.70        49\n           9       0.81      0.93      0.87        60\n\n    accuracy                           0.62       418\n   macro avg       0.64      0.61      0.60       418\nweighted avg       0.64      0.62      0.60       418\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        31\n           1       0.50      0.81      0.62        27\n           2       0.55      0.78      0.64        36\n           3       0.67      0.22      0.33        36\n           4       0.44      0.41      0.42        41\n           5       0.90      0.18      0.31        49\n           6       0.50      0.11      0.18        45\n           7       0.31      0.77      0.44        44\n           8       0.81      0.68      0.74        50\n           9       0.71      0.83      0.76        58\n\n    accuracy                           0.57       417\n   macro avg       0.64      0.58      0.55       417\nweighted avg       0.64      0.57      0.54       417\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      0.97      0.98        30\n           1       0.75      0.69      0.72        26\n           2       0.67      0.41      0.51        34\n           3       0.75      0.38      0.50        32\n           4       0.37      0.37      0.37        38\n           5       0.48      0.62      0.55        48\n           6       0.46      0.51      0.48        45\n           7       0.41      0.73      0.52        44\n           8       0.91      0.56      0.69        52\n           9       0.86      0.84      0.85        57\n\n    accuracy                           0.61       406\n   macro avg       0.67      0.61      0.62       406\nweighted avg       0.66      0.61      0.62       406\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        34\n           1       1.00      0.15      0.27        26\n           2       0.56      0.54      0.55        35\n           3       0.55      0.58      0.57        36\n           4       0.40      0.57      0.47        44\n           5       0.58      0.76      0.66        46\n           6       0.51      0.45      0.48        49\n           7       0.57      0.74      0.65        43\n           8       0.77      0.50      0.61        54\n           9       0.84      0.84      0.84        57\n\n    accuracy                           0.63       424\n   macro avg       0.68      0.61      0.61       424\nweighted avg       0.67      0.63      0.62       424\n"
      ]
    },
    "800-809": {
      "target_sums": [
        800,
        801,
        802,
        803,
        804,
        805,
        806,
        807,
        808,
        809
      ],
      "n_classes": 10,
      "generation_accuracies_reps": [
        0.53525,
        0.53425,
        0.534,
        0.54425,
        0.53075
      ],
      "original_sample_counts_reps": [
        4000,
        4000,
        4000,
        4000,
        4000
      ],
      "filtered_sample_counts_reps": [
        2141,
        2137,
        2136,
        2177,
        2123
      ],
      "probe_accuracies_per_layer_reps": {
        "1": [
          0.1445221445221445,
          0.10981308411214953,
          0.09579439252336448,
          0.1353211009174312,
          0.11058823529411765
        ],
        "2": [
          0.1282051282051282,
          0.08411214953271028,
          0.1308411214953271,
          0.12155963302752294,
          0.11529411764705882
        ],
        "3": [
          0.11655011655011654,
          0.1542056074766355,
          0.1261682242990654,
          0.12844036697247707,
          0.13176470588235295
        ],
        "4": [
          0.11655011655011654,
          0.11214953271028037,
          0.1191588785046729,
          0.10550458715596331,
          0.16705882352941176
        ],
        "5": [
          0.10955710955710955,
          0.14485981308411214,
          0.11682242990654206,
          0.16972477064220184,
          0.1811764705882353
        ],
        "6": [
          0.14918414918414918,
          0.17289719626168223,
          0.14485981308411214,
          0.12614678899082568,
          0.12705882352941175
        ],
        "7": [
          0.13286713286713286,
          0.1191588785046729,
          0.1378504672897196,
          0.17660550458715596,
          0.17176470588235293
        ],
        "8": [
          0.20046620046620048,
          0.1985981308411215,
          0.15186915887850466,
          0.11697247706422019,
          0.2
        ],
        "9": [
          0.1585081585081585,
          0.14485981308411214,
          0.16355140186915887,
          0.13761467889908258,
          0.18823529411764706
        ],
        "10": [
          0.2517482517482518,
          0.2616822429906542,
          0.24065420560747663,
          0.268348623853211,
          0.28941176470588237
        ],
        "11": [
          0.19813519813519814,
          0.2570093457943925,
          0.3037383177570093,
          0.18577981651376146,
          0.24705882352941178
        ],
        "12": [
          0.23076923076923078,
          0.2616822429906542,
          0.26635514018691586,
          0.21100917431192662,
          0.27058823529411763
        ],
        "13": [
          0.2517482517482518,
          0.2850467289719626,
          0.3014018691588785,
          0.23853211009174313,
          0.2635294117647059
        ],
        "14": [
          0.317016317016317,
          0.3014018691588785,
          0.3341121495327103,
          0.268348623853211,
          0.2564705882352941
        ],
        "15": [
          0.289044289044289,
          0.2897196261682243,
          0.31542056074766356,
          0.28211009174311924,
          0.26823529411764707
        ],
        "16": [
          0.2261072261072261,
          0.34813084112149534,
          0.29205607476635514,
          0.25229357798165136,
          0.24235294117647058
        ],
        "17": [
          0.4219114219114219,
          0.4532710280373832,
          0.4883177570093458,
          0.4518348623853211,
          0.4541176470588235
        ],
        "18": [
          0.38927738927738925,
          0.4719626168224299,
          0.4976635514018692,
          0.4288990825688073,
          0.5882352941176471
        ],
        "19": [
          0.5547785547785548,
          0.6191588785046729,
          0.6121495327102804,
          0.6605504587155964,
          0.6517647058823529
        ],
        "20": [
          0.6526806526806527,
          0.6308411214953271,
          0.6705607476635514,
          0.6077981651376146,
          0.5552941176470588
        ],
        "21": [
          0.5547785547785548,
          0.6004672897196262,
          0.5957943925233645,
          0.5412844036697247,
          0.5811764705882353
        ],
        "22": [
          0.6130536130536131,
          0.5864485981308412,
          0.6822429906542056,
          0.5986238532110092,
          0.6352941176470588
        ],
        "23": [
          0.585081585081585,
          0.5116822429906542,
          0.5373831775700935,
          0.45642201834862384,
          0.52
        ],
        "24": [
          0.6596736596736597,
          0.602803738317757,
          0.5654205607476636,
          0.5527522935779816,
          0.6352941176470588
        ],
        "25": [
          0.585081585081585,
          0.5911214953271028,
          0.5911214953271028,
          0.5504587155963303,
          0.5811764705882353
        ],
        "26": [
          0.6037296037296037,
          0.5841121495327103,
          0.5280373831775701,
          0.5229357798165137,
          0.5858823529411765
        ],
        "27": [
          0.6433566433566433,
          0.5864485981308412,
          0.5,
          0.5160550458715596,
          0.5647058823529412
        ],
        "28": [
          0.5710955710955711,
          0.5280373831775701,
          0.5467289719626168,
          0.4243119266055046,
          0.5411764705882353
        ]
      },
      "best_layer_indices_reps": [
        24,
        20,
        22,
        19,
        19
      ],
      "best_layer_accuracies_reps": [
        0.6596736596736597,
        0.6308411214953271,
        0.6822429906542056,
        0.6605504587155964,
        0.6517647058823529
      ],
      "best_layer_reports_reps": [
        "              precision    recall  f1-score   support\n\n           0       1.00      0.97      0.99        34\n           1       1.00      0.32      0.49        28\n           2       0.49      0.79      0.61        34\n           3       0.42      0.83      0.56        36\n           4       0.92      0.50      0.65        48\n           5       0.70      0.47      0.56        49\n           6       0.53      0.39      0.45        49\n           7       0.78      0.65      0.70        48\n           8       0.53      0.86      0.66        51\n           9       1.00      0.83      0.91        52\n\n    accuracy                           0.66       429\n   macro avg       0.74      0.66      0.66       429\nweighted avg       0.73      0.66      0.66       429\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        35\n           1       0.68      0.54      0.60        24\n           2       0.40      0.51      0.45        35\n           3       0.72      0.58      0.65        36\n           4       0.64      0.73      0.68        48\n           5       0.62      0.65      0.63        49\n           6       0.00      0.00      0.00        46\n           7       0.78      0.30      0.44        46\n           8       0.47      0.93      0.63        55\n           9       0.76      0.94      0.84        54\n\n    accuracy                           0.63       428\n   macro avg       0.61      0.62      0.59       428\nweighted avg       0.60      0.63      0.59       428\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      0.86      0.93        37\n           1       0.76      0.52      0.62        25\n           2       0.75      0.69      0.72        35\n           3       0.40      0.50      0.44        32\n           4       0.66      0.69      0.67        45\n           5       0.51      0.67      0.58        49\n           6       0.56      0.58      0.57        48\n           7       0.61      0.46      0.52        50\n           8       0.75      0.75      0.75        52\n           9       0.96      0.96      0.96        55\n\n    accuracy                           0.68       428\n   macro avg       0.70      0.67      0.68       428\nweighted avg       0.70      0.68      0.69       428\n",
        "              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.99        33\n           1       0.46      0.82      0.59        22\n           2       0.86      0.34      0.49        35\n           3       0.76      0.33      0.46        40\n           4       0.48      0.83      0.61        48\n           5       0.63      0.82      0.71        50\n           6       0.55      0.70      0.62        53\n           7       0.63      0.47      0.54        51\n           8       0.85      0.45      0.59        51\n           9       0.90      0.89      0.90        53\n\n    accuracy                           0.66       436\n   macro avg       0.71      0.66      0.65       436\nweighted avg       0.71      0.66      0.65       436\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        38\n           1       0.92      0.55      0.69        22\n           2       1.00      0.08      0.15        36\n           3       0.46      0.47      0.46        34\n           4       0.65      0.77      0.71        47\n           5       0.50      0.86      0.63        43\n           6       0.43      0.94      0.59        49\n           7       0.78      0.38      0.51        48\n           8       0.86      0.37      0.51        52\n           9       0.96      0.93      0.95        56\n\n    accuracy                           0.65       425\n   macro avg       0.76      0.63      0.62       425\nweighted avg       0.75      0.65      0.63       425\n"
      ]
    },
    "900-909": {
      "target_sums": [
        900,
        901,
        902,
        903,
        904,
        905,
        906,
        907,
        908,
        909
      ],
      "n_classes": 10,
      "generation_accuracies_reps": [
        0.732,
        0.7295,
        0.731,
        0.72175,
        0.719
      ],
      "original_sample_counts_reps": [
        4000,
        4000,
        4000,
        4000,
        4000
      ],
      "filtered_sample_counts_reps": [
        2928,
        2918,
        2924,
        2887,
        2876
      ],
      "probe_accuracies_per_layer_reps": {
        "1": [
          0.10921501706484642,
          0.136986301369863,
          0.11794871794871795,
          0.1245674740484429,
          0.11458333333333333
        ],
        "2": [
          0.11604095563139932,
          0.12157534246575342,
          0.10598290598290598,
          0.11764705882352941,
          0.109375
        ],
        "3": [
          0.08873720136518772,
          0.1267123287671233,
          0.1675213675213675,
          0.10899653979238755,
          0.10069444444444445
        ],
        "4": [
          0.13139931740614336,
          0.09246575342465753,
          0.1264957264957265,
          0.10726643598615918,
          0.13194444444444445
        ],
        "5": [
          0.14334470989761092,
          0.11643835616438356,
          0.1264957264957265,
          0.16262975778546712,
          0.13194444444444445
        ],
        "6": [
          0.12286689419795221,
          0.15753424657534246,
          0.11965811965811966,
          0.09688581314878893,
          0.12152777777777778
        ],
        "7": [
          0.14334470989761092,
          0.11643835616438356,
          0.15042735042735042,
          0.10553633217993079,
          0.14583333333333334
        ],
        "8": [
          0.1621160409556314,
          0.14897260273972604,
          0.11623931623931624,
          0.14878892733564014,
          0.1267361111111111
        ],
        "9": [
          0.16723549488054607,
          0.1267123287671233,
          0.17435897435897435,
          0.14359861591695502,
          0.1840277777777778
        ],
        "10": [
          0.26791808873720135,
          0.273972602739726,
          0.27350427350427353,
          0.20761245674740483,
          0.2673611111111111
        ],
        "11": [
          0.30716723549488056,
          0.2688356164383562,
          0.23931623931623933,
          0.21972318339100347,
          0.20833333333333334
        ],
        "12": [
          0.2815699658703072,
          0.2722602739726027,
          0.23076923076923078,
          0.13494809688581316,
          0.24479166666666666
        ],
        "13": [
          0.24061433447098976,
          0.2534246575342466,
          0.305982905982906,
          0.2629757785467128,
          0.2170138888888889
        ],
        "14": [
          0.29692832764505117,
          0.2688356164383562,
          0.2717948717948718,
          0.21972318339100347,
          0.2204861111111111
        ],
        "15": [
          0.2935153583617747,
          0.2996575342465753,
          0.24615384615384617,
          0.17128027681660898,
          0.2864583333333333
        ],
        "16": [
          0.257679180887372,
          0.2791095890410959,
          0.29743589743589743,
          0.12802768166089964,
          0.22395833333333334
        ],
        "17": [
          0.4761092150170648,
          0.4691780821917808,
          0.39145299145299145,
          0.2906574394463668,
          0.4288194444444444
        ],
        "18": [
          0.46928327645051193,
          0.4571917808219178,
          0.48547008547008547,
          0.3754325259515571,
          0.4913194444444444
        ],
        "19": [
          0.6126279863481229,
          0.6438356164383562,
          0.5777777777777777,
          0.6349480968858131,
          0.5902777777777778
        ],
        "20": [
          0.6262798634812287,
          0.6455479452054794,
          0.5709401709401709,
          0.5449826989619377,
          0.6111111111111112
        ],
        "21": [
          0.537542662116041,
          0.5976027397260274,
          0.5401709401709401,
          0.49480968858131485,
          0.609375
        ],
        "22": [
          0.6296928327645052,
          0.5907534246575342,
          0.6478632478632479,
          0.5951557093425606,
          0.6180555555555556
        ],
        "23": [
          0.5290102389078498,
          0.5821917808219178,
          0.5367521367521367,
          0.4982698961937716,
          0.5347222222222222
        ],
        "24": [
          0.5477815699658704,
          0.553082191780822,
          0.6102564102564103,
          0.5397923875432526,
          0.59375
        ],
        "25": [
          0.5614334470989761,
          0.6506849315068494,
          0.5572649572649573,
          0.5813148788927336,
          0.5885416666666666
        ],
        "26": [
          0.5187713310580204,
          0.6044520547945206,
          0.6205128205128205,
          0.48961937716262977,
          0.5746527777777778
        ],
        "27": [
          0.5597269624573379,
          0.5736301369863014,
          0.6034188034188034,
          0.5692041522491349,
          0.5729166666666666
        ],
        "28": [
          0.5733788395904437,
          0.583904109589041,
          0.6222222222222222,
          0.610726643598616,
          0.5920138888888888
        ]
      },
      "best_layer_indices_reps": [
        22,
        25,
        22,
        19,
        22
      ],
      "best_layer_accuracies_reps": [
        0.6296928327645052,
        0.6506849315068494,
        0.6478632478632479,
        0.6349480968858131,
        0.6180555555555556
      ],
      "best_layer_reports_reps": [
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        56\n           1       0.50      0.77      0.61        48\n           2       0.41      0.87      0.56        52\n           3       0.88      0.13      0.23        52\n           4       0.69      0.30      0.42        60\n           5       0.45      0.56      0.50        61\n           6       0.83      0.24      0.38        62\n           7       0.79      0.51      0.62        61\n           8       0.69      0.89      0.78        66\n           9       0.71      0.99      0.83        68\n\n    accuracy                           0.63       586\n   macro avg       0.70      0.63      0.59       586\nweighted avg       0.70      0.63      0.60       586\n",
        "              precision    recall  f1-score   support\n\n           0       0.93      1.00      0.96        54\n           1       0.68      0.71      0.70        45\n           2       0.73      0.62      0.67        53\n           3       0.58      0.56      0.57        54\n           4       0.56      0.62      0.59        56\n           5       0.53      0.44      0.48        61\n           6       0.62      0.38      0.48        65\n           7       0.56      0.58      0.57        60\n           8       0.65      0.69      0.67        68\n           9       0.67      0.91      0.77        68\n\n    accuracy                           0.65       584\n   macro avg       0.65      0.65      0.65       584\nweighted avg       0.65      0.65      0.64       584\n",
        "              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98        52\n           1       0.57      0.67      0.62        42\n           2       0.60      0.40      0.48        52\n           3       0.78      0.54      0.64        54\n           4       0.36      0.80      0.50        61\n           5       0.62      0.81      0.70        62\n           6       0.67      0.29      0.40        63\n           7       0.75      0.68      0.71        59\n           8       0.60      0.35      0.44        69\n           9       0.91      0.96      0.93        71\n\n    accuracy                           0.65       585\n   macro avg       0.68      0.65      0.64       585\nweighted avg       0.69      0.65      0.64       585\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      0.98      0.99        55\n           1       0.65      0.62      0.63        42\n           2       1.00      0.06      0.11        51\n           3       0.79      0.28      0.42        53\n           4       0.46      0.65      0.54        55\n           5       0.58      0.73      0.65        62\n           6       0.41      0.83      0.55        64\n           7       0.58      0.83      0.68        60\n           8       0.81      0.38      0.51        69\n           9       0.98      0.88      0.93        67\n\n    accuracy                           0.63       578\n   macro avg       0.73      0.62      0.60       578\nweighted avg       0.73      0.63      0.61       578\n",
        "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        55\n           1       1.00      0.05      0.09        42\n           2       0.65      0.69      0.67        51\n           3       0.46      0.81      0.58        52\n           4       0.70      0.28      0.40        57\n           5       0.80      0.20      0.32        60\n           6       0.64      0.37      0.46        63\n           7       0.47      0.90      0.62        62\n           8       0.47      0.91      0.62        64\n           9       1.00      0.81      0.90        70\n\n    accuracy                           0.62       576\n   macro avg       0.72      0.60      0.57       576\nweighted avg       0.71      0.62      0.58       576\n"
      ]
    }
  },
  "best_layer_mode_per_range": {
    "500-509": 26,
    "600-609": 20,
    "700-709": 25,
    "800-809": 19,
    "900-909": 22
  }
}