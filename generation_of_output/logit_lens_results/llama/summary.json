{
  "model_id": "llama",
  "model_path": "/root/autodl-tmp/llama",
  "timestamp": "2025-09-09T17:14:03.828161",
  "params": {
    "NUM_DATASET_SAMPLES": 1000,
    "NUM_REPETITIONS": 5,
    "BASE_SEED": 42,
    "MAX_INPUT_LENGTH": 512,
    "MAX_NEW_TOKENS": 1,
    "DO_SAMPLE": false
  },
  "num_layers": 33,
  "display_last_n_layers": 10,
  "mean_counts_per_layer": [
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    4.8,
    2.4,
    30.4,
    49.2,
    126.2,
    119.6,
    137.8,
    78.6,
    222.6,
    210.4,
    12.4,
    5.6
  ],
  "std_err_counts_per_layer": [
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.8197560612767679,
    0.4560701700396552,
    0.9633275663033838,
    1.4532721699667959,
    7.073330191642406,
    3.7159117319979487,
    3.4339481650135606,
    3.041052449399714,
    3.737378760575385,
    6.648909685053633,
    0.8294576541331088,
    0.920869154657707
  ],
  "never_top1_counts_per_run": [
    0,
    0,
    0,
    0,
    0
  ],
  "mean_never_top1": 0.0,
  "stddev_never_top1": 0.0,
  "stderr_never_top1": 0.0
}