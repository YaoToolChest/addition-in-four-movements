{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467986e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# --- 依赖检查 ---\n",
    "try:\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "    import torch\n",
    "except ImportError:\n",
    "    print(\"错误：未找到 'transformers' 或 'torch' 库。请先安装： pip install torch transformers accelerate\")\n",
    "    exit()\n",
    "\n",
    "# =============================================================================\n",
    "# 配置：可见 GPU + 统一使用 \"cuda\"\n",
    "# - 如需指定某张卡，建议在启动前设置环境变量：\n",
    "#   export CUDA_VISIBLE_DEVICES=1\n",
    "#   然后本脚本会统一使用 \"cuda\"\n",
    "# =============================================================================\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- 配置 ---\n",
    "# 要测试的模型ID列表\n",
    "model_ids_to_test = [\n",
    "\"/root/autodl-tmp/llama\",\n",
    "\"/root/autodl-tmp/Mistral\",\n",
    "\"/root/autodl-tmp/Qwen2.5-Math-7B\",\n",
    "\"/root/autodl-tmp/AceMath\"\n",
    "]\n",
    "# 每个随机位数类别测试的数量\n",
    "num_random_tests = 4000  # 你原来是 4000\n",
    "\n",
    "# 推理时使用的批量大小\n",
    "BATCH_SIZE = 1000  # 若 OOM 请手动调小\n",
    "# 日志文件配置\n",
    "log_directory = \"test1_logs\"\n",
    "os.makedirs(log_directory, exist_ok=True)\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file_name = os.path.join(log_directory, f\"llm_addition_test_log_{timestamp}.txt\")\n",
    "\n",
    "# --- 输入长度一致性控制 ---\n",
    "ENFORCE_UNIFORM_INPUT_LEN = True         # 开启后，若每条样本输入 token 长度不同，直接抛异常\n",
    "EXPECTED_PROMPT_TOKENS = None            # 若你已知道固定提示 token 长度，可填正整数做更严格校验；否则保持 None\n",
    "\n",
    "# --- 全局变量 ---\n",
    "current_log_file = None\n",
    "\n",
    "# --- 日志函数 ---\n",
    "def log_message(message, print_to_console=True):\n",
    "    \"\"\"将消息写入日志文件并可选择打印到控制台\"\"\"\n",
    "    global current_log_file\n",
    "    if current_log_file:\n",
    "        with open(current_log_file, 'a', encoding='utf-8') as f:\n",
    "            f.write(message + \"\\n\")\n",
    "    if print_to_console:\n",
    "        print(message)\n",
    "\n",
    "# --- 模型调用函数 (批量处理，含长度断言) ---\n",
    "def get_model_responses_batch(prompts: list, model, tokenizer, device):\n",
    "    if model is None or tokenizer is None:\n",
    "        return [\"[模型未加载]\" for _ in prompts]\n",
    "\n",
    "    try:\n",
    "        # 注意：保持你已有的提示模板（本函数不强行套 chat 模板）\n",
    "        inputs = tokenizer(\n",
    "            prompts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "\n",
    "        # 迁移到统一设备\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # 计算每个样本真实输入长度，并进行一致性断言\n",
    "        attn = inputs[\"attention_mask\"]  # [B, T]\n",
    "        input_lens = attn.sum(dim=1)     # [B]\n",
    "        min_len = int(input_lens.min().item())\n",
    "        max_len = int(input_lens.max().item())\n",
    "\n",
    "        if ENFORCE_UNIFORM_INPUT_LEN:\n",
    "            assert min_len == max_len, (\n",
    "                f\"[长度不一致] 最小={min_len}, 最大={max_len}, 每条长度={input_lens.tolist()}\"\n",
    "            )\n",
    "        if EXPECTED_PROMPT_TOKENS is not None:\n",
    "            assert max_len == EXPECTED_PROMPT_TOKENS, (\n",
    "                f\"[长度异常] 期望={EXPECTED_PROMPT_TOKENS}, 实得={max_len}\"\n",
    "            )\n",
    "\n",
    "        # 统一切片起点（既然长度一致，用 max_len 即可）\n",
    "        num_input_tokens = max_len\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                max_new_tokens=1,  # 保持你原值；若只需输出整数，可适当调小\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                do_sample=False,\n",
    "                use_cache=True,\n",
    "                return_dict_in_generate=False\n",
    "            )\n",
    "\n",
    "        responses_text = []\n",
    "        for i in range(outputs.shape[0]):\n",
    "            response_ids = outputs[i][num_input_tokens:]\n",
    "            response_text = tokenizer.decode(response_ids, skip_special_tokens=True).strip()\n",
    "            responses_text.append(response_text)\n",
    "        return responses_text\n",
    "\n",
    "    except AssertionError as ae:\n",
    "        log_message(f\"断言失败：{ae}\", print_to_console=True)\n",
    "        # 将异常抛出，让上层能快速定位到长度控制问题\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        log_message(f\"模型批量生成过程中出错: {e} (处理中批量大小: {len(prompts)})\", print_to_console=True)\n",
    "        return [\"[生成错误]\" for _ in prompts]\n",
    "\n",
    "# --- 响应解析函数（保持你原实现） ---\n",
    "def parse_response(response_text):\n",
    "    match = re.search(r'(-?\\d+)', response_text)\n",
    "    if match:\n",
    "        try:\n",
    "            return int(match.group(1))\n",
    "        except ValueError:\n",
    "            log_message(f\" [警告: 解析的数字过大或无效 '{match.group(1)}']\", print_to_console=False)\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# --- 辅助函数：获取数字位数类别 ---\n",
    "def get_digit_category(n1, n2):\n",
    "    len1 = len(str(abs(n1)))\n",
    "    len2 = len(str(abs(n2)))\n",
    "    max_digits = max(len1, len2)\n",
    "    return f\"{max_digits}-digit\"\n",
    "\n",
    "# --- 批量测试运行函数 ---\n",
    "def run_batch_test(test_cases_xy: list, category_name: str, stats_dict: defaultdict, batch_size: int, model, tokenizer, device):\n",
    "    if not test_cases_xy:\n",
    "        return\n",
    "\n",
    "    stats_dict[category_name]['total'] += len(test_cases_xy)\n",
    "\n",
    "    num_processed_in_category = 0\n",
    "    for i in range(0, len(test_cases_xy), batch_size):\n",
    "        current_batch_xy = test_cases_xy[i : i + batch_size]\n",
    "        if not current_batch_xy:\n",
    "            continue\n",
    "\n",
    "        prompts_chunk = []\n",
    "        correct_answers_chunk = []\n",
    "        for x, y in current_batch_xy:\n",
    "            prompts_chunk.append(f\"Calculate: {x}+{y} = \")\n",
    "            correct_answers_chunk.append(x + y)\n",
    "\n",
    "        raw_responses_chunk = get_model_responses_batch(prompts_chunk, model, tokenizer, device)\n",
    "\n",
    "        for j in range(len(raw_responses_chunk)):\n",
    "            prompt_text = prompts_chunk[j]\n",
    "            correct_answer = correct_answers_chunk[j]\n",
    "            raw_response = raw_responses_chunk[j]\n",
    "            num_processed_in_category += 1\n",
    "\n",
    "            log_line_prefix = f\"测试 ({category_name} {num_processed_in_category}/{len(test_cases_xy)}): {prompt_text}\"\n",
    "            model_answer = parse_response(raw_response)\n",
    "\n",
    "            result_log = f\"模型原始输出: '{raw_response}' -> \"\n",
    "            if model_answer is not None:\n",
    "                if model_answer == correct_answer:\n",
    "                    result_log += f\"结果: {model_answer} (正确)\"\n",
    "                    stats_dict[category_name]['correct'] += 1\n",
    "                else:\n",
    "                    result_log += f\"结果: {model_answer} (错误! 正确答案是 {correct_answer})\"\n",
    "            else:\n",
    "                if raw_response == \"[模型未加载]\":\n",
    "                    result_log += \"结果: 模型未加载\"\n",
    "                elif raw_response == \"[生成错误]\":\n",
    "                    result_log += \"结果: 模型生成错误\"\n",
    "                elif not raw_response:\n",
    "                    result_log += \"结果: 模型无输出\"\n",
    "                else:\n",
    "                    result_log += f\"结果: 无法解析模型输出 ('{raw_response}')\"\n",
    "            log_message(f\"{log_line_prefix}{result_log}\", print_to_console=True)\n",
    "\n",
    "# --- 函数：为 N-digit + N-digit 类别生成并运行测试 ---\n",
    "def generate_and_run_specific_digit_sum_tests(num_digits_operands, num_tests, stats, batch_size_param, model, tokenizer, device):\n",
    "    category_name = f\"{num_digits_operands}-digit+{num_digits_operands}-digit\"  # 例如 \"2-digit+2-digit\"\n",
    "    log_message(f\"\\n--- {category_name} 测试 ({num_tests}次) ---\", print_to_console=True)\n",
    "    test_cases = []\n",
    "\n",
    "    if num_digits_operands == 1:\n",
    "        lower_bound = 0\n",
    "        upper_bound = 9\n",
    "    else:\n",
    "        lower_bound = 10**(num_digits_operands - 1)\n",
    "        upper_bound = (10**num_digits_operands) - 1\n",
    "\n",
    "    for _ in range(num_tests):\n",
    "        x = random.randint(lower_bound, upper_bound)\n",
    "        y = random.randint(lower_bound, upper_bound)\n",
    "        test_cases.append((x, y))\n",
    "    run_batch_test(test_cases, category_name, stats, batch_size_param, model, tokenizer, device)\n",
    "\n",
    "# --- 辅助函数：用于排序类别名称 ---\n",
    "def sort_key_func(k):\n",
    "    # 匹配 \"N-digit+M-digit\"\n",
    "    match_n_plus_m = re.search(r'(\\d+)-digit\\+(\\d+)-digit', k)\n",
    "    if match_n_plus_m:\n",
    "        return (0, int(match_n_plus_m.group(1)), int(match_n_plus_m.group(2)))\n",
    "    # 匹配 \"N-digit\"\n",
    "    match_n_digit = re.search(r'(\\d+)-digit', k)\n",
    "    if match_n_digit:\n",
    "        return (1, int(match_n_digit.group(1)))\n",
    "    return (2, k)\n",
    "\n",
    "# --- 模型加载（单设备，统一 .to(DEVICE)） ---\n",
    "def load_model_single_device(model_id: str, device: str = DEVICE):\n",
    "    # dtype 选择：GPU 优先 bf16（若支持），其次 fp16；CPU 用 fp32\n",
    "    if device.startswith(\"cuda\") and torch.cuda.is_available():\n",
    "        try:\n",
    "            bf16_ok = torch.cuda.is_bf16_supported()\n",
    "        except Exception:\n",
    "            bf16_ok = False\n",
    "        dtype = torch.bfloat16 if bf16_ok else torch.float16\n",
    "    else:\n",
    "        dtype = torch.float32\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=dtype,\n",
    "        device_map=None,           # 关键：不使用 device_map\n",
    "        low_cpu_mem_usage=True\n",
    "    ).eval()\n",
    "\n",
    "    model.to(device)              # 统一迁移到单一设备\n",
    "    return model, tokenizer\n",
    "\n",
    "# --- 主测试循环 ---\n",
    "def main():\n",
    "    global current_log_file\n",
    "    current_log_file = log_file_name\n",
    "    log_message(f\"测试日志将保存在: {log_file_name}\", print_to_console=True)\n",
    "    log_message(f\"测试开始时间: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", print_to_console=True)\n",
    "\n",
    "    all_models_summary_stats = []\n",
    "\n",
    "    for model_idx, current_model_id in enumerate(model_ids_to_test):\n",
    "        log_message(\"\\n\" + \"=\"*50, print_to_console=True)\n",
    "        log_message(f\"开始测试模型 {model_idx+1}/{len(model_ids_to_test)}: {current_model_id}\", print_to_console=True)\n",
    "        log_message(\"=\"*50, print_to_console=True)\n",
    "\n",
    "        model = None\n",
    "        tokenizer = None\n",
    "        log_message(f\"尝试使用设备: {DEVICE}（通过 CUDA_VISIBLE_DEVICES 控制可见 GPU）\", print_to_console=True)\n",
    "\n",
    "        model_load_start_time = time.time()\n",
    "        try:\n",
    "            model, tokenizer = load_model_single_device(current_model_id, device=DEVICE)\n",
    "            model_load_time = time.time() - model_load_start_time\n",
    "            log_message(f\"成功加载模型和分词器: {current_model_id} (耗时: {model_load_time:.2f} 秒)\", print_to_console=True)\n",
    "\n",
    "            current_model_summary = {\n",
    "                'model_id': current_model_id,\n",
    "                'status': 'Success',\n",
    "                'load_time_seconds': f\"{model_load_time:.2f}\",\n",
    "                'overall_accuracy': 'N/A',\n",
    "                'category_accuracies': {}\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            model_load_time = time.time() - model_load_start_time\n",
    "            log_message(f\"错误：无法加载模型 '{current_model_id}'. 错误: {e} (尝试加载耗时: {model_load_time:.2f} 秒)\", print_to_console=True)\n",
    "            log_message(\"跳过此模型的测试。\", print_to_console=True)\n",
    "            all_models_summary_stats.append({\n",
    "                'model_id': current_model_id,\n",
    "                'status': 'Load Failed',\n",
    "                'load_time_seconds': f\"{model_load_time:.2f}\",\n",
    "                'overall_accuracy': 'N/A',\n",
    "                'category_accuracies': {}\n",
    "            })\n",
    "            if model is not None: del model\n",
    "            if tokenizer is not None: del tokenizer\n",
    "            if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "            continue\n",
    "\n",
    "        stats_by_digits = defaultdict(lambda: {'total': 0, 'correct': 0})\n",
    "        log_message(f\"\\n开始大语言模型 ({current_model_id}) 加法能力测试 (每类随机测试 {num_random_tests} 次, 批量大小: {BATCH_SIZE})...\", print_to_console=True)\n",
    "\n",
    "        # --- 基本测试 ---\n",
    "        log_message(\"\\n--- 基本测试 ---\", print_to_console=True)\n",
    "        tests_basic_tuples = [(0, 0), (0, 1), (5, 8), (10, 25), (123, 0)]\n",
    "        categorized_basic_tests = defaultdict(list)\n",
    "        for x, y in tests_basic_tuples:\n",
    "            category = get_digit_category(x, y)\n",
    "            categorized_basic_tests[category].append((x, y))\n",
    "\n",
    "        for category, cases in categorized_basic_tests.items():\n",
    "            log_message(f\"处理基本测试类别: {category} ({len(cases)} 个案例)\", print_to_console=True)\n",
    "            run_batch_test(cases, category, stats_by_digits, BATCH_SIZE, model, tokenizer, DEVICE)\n",
    "\n",
    "        # --- N-digit + N-digit 测试 (1+1 到 4+4位) ---\n",
    "        log_message(\"\\n--- N-digit + N-digit 加法专项测试 ---\", print_to_console=True)\n",
    "        for num_digits_val in range(1, 5):  # 从1位数+1位数 到 4位数+4位数\n",
    "            generate_and_run_specific_digit_sum_tests(num_digits_val, num_random_tests, stats_by_digits, BATCH_SIZE, model, tokenizer, DEVICE)\n",
    "\n",
    "        # --- 进位复杂情况测试 ---\n",
    "        log_message(\"\\n--- 进位复杂情况测试 ---\", print_to_console=True)\n",
    "        tests_carry_tuples = [\n",
    "            (9, 9), (8, 7), (99, 99), (88, 77), (999, 999), (1, 999),\n",
    "            (9999, 9999), (1234, 8765), (99999, 99999), (1, 99999),\n",
    "            (999999, 999999), (123456, 876543)\n",
    "        ]\n",
    "        categorized_carry_tests = defaultdict(list)\n",
    "        for x, y in tests_carry_tuples:\n",
    "            category = get_digit_category(x, y)\n",
    "            categorized_carry_tests[category].append((x, y))\n",
    "\n",
    "        sorted_carry_test_items = sorted(categorized_carry_tests.items(), key=lambda item: sort_key_func(item[0]))\n",
    "        for category, cases in sorted_carry_test_items:\n",
    "            log_message(f\"处理进位测试类别: {category} ({len(cases)} 个案例)\", print_to_console=True)\n",
    "            run_batch_test(cases, category, stats_by_digits, BATCH_SIZE, model, tokenizer, DEVICE)\n",
    "\n",
    "        # --- 当前模型的最终统计 ---\n",
    "        log_message(\"\\n\" + \"=\"*40, print_to_console=True)\n",
    "        log_message(f\" 测试统计结果: {current_model_id}\", print_to_console=True)\n",
    "        log_message(\" (按操作数位数或类型分类)\", print_to_console=True)\n",
    "        log_message(\"=\"*40, print_to_console=True)\n",
    "\n",
    "        total_overall = 0\n",
    "        correct_overall = 0\n",
    "\n",
    "        category_accuracies_for_current_model = {}\n",
    "        sorted_category_keys_for_model = sorted(stats_by_digits.keys(), key=sort_key_func)\n",
    "\n",
    "        for category in sorted_category_keys_for_model:\n",
    "            stats = stats_by_digits[category]\n",
    "            total = stats['total']\n",
    "            correct = stats['correct']\n",
    "            total_overall += total\n",
    "            correct_overall += correct\n",
    "            accuracy_str = \"N/A\"\n",
    "            if total > 0:\n",
    "                accuracy = (correct / total) * 100\n",
    "                accuracy_str = f\"{accuracy:.2f}%\"\n",
    "                log_message(f\"类别: {category.rjust(18)} | 总数: {str(total).rjust(4)} | 正确: {str(correct).rjust(4)} | 准确率: {accuracy_str.rjust(7)}\", print_to_console=True)\n",
    "            else:\n",
    "                is_expected_category = category in categorized_basic_tests or \\\n",
    "                                       category in categorized_carry_tests or \\\n",
    "                                       any(f\"{d}-digit+{d}-digit\" == category for d in range(1, 5)) or \\\n",
    "                                       any(f\"{d}-digit\" == category for d in range(1, 7))\n",
    "                if is_expected_category:\n",
    "                    log_message(f\"类别: {category.rjust(18)} | 总数: {str(total).rjust(4)} | 正确: {str(correct).rjust(4)} | 准确率: {accuracy_str.rjust(7)}\", print_to_console=True)\n",
    "            category_accuracies_for_current_model[category] = accuracy_str\n",
    "\n",
    "        current_model_summary['category_accuracies'] = category_accuracies_for_current_model\n",
    "\n",
    "        log_message(\"-\"*40, print_to_console=True)\n",
    "        if total_overall > 0:\n",
    "            overall_accuracy_val = (correct_overall / total_overall) * 100\n",
    "            overall_accuracy_str = f\"{overall_accuracy_val:.2f}%\"\n",
    "            log_message(f\"总体 {' '.rjust(18)} | 总数: {str(total_overall).rjust(4)} | 正确: {str(correct_overall).rjust(4)} | 准确率: {overall_accuracy_str.rjust(7)}\", print_to_console=True)\n",
    "            current_model_summary['overall_accuracy'] = overall_accuracy_str\n",
    "        else:\n",
    "            log_message(f\"总体 {' '.rjust(18)} | 总数: {str(0).rjust(4)} | 正确: {str(0).rjust(4)} | 准确率: {'N/A'.rjust(7)}\", print_to_console=True)\n",
    "            current_model_summary['overall_accuracy'] = 'N/A'\n",
    "\n",
    "        all_models_summary_stats.append(current_model_summary)\n",
    "        log_message(\"=\"*40, print_to_console=True)\n",
    "\n",
    "        log_message(f\"完成模型 {current_model_id} 的测试。卸载模型...\", print_to_console=True)\n",
    "        del model\n",
    "        del tokenizer\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        log_message(f\"模型 {current_model_id} 已卸载。\", print_to_console=True)\n",
    "\n",
    "    # --- 所有模型测试完成后的最终摘要表 ---\n",
    "    log_message(\"\\n\\n\" + \"=\"*120, print_to_console=True)\n",
    "    log_message(\" \" * 45 + \"总体模型性能摘要\" + \" \" * 45, print_to_console=True)\n",
    "    log_message(\"=\"*120, print_to_console=True)\n",
    "\n",
    "    max_model_id_len = max(len(s['model_id']) for s in all_models_summary_stats) if all_models_summary_stats else 20\n",
    "    max_model_id_len = max(max_model_id_len, len(\"模型 ID\"))\n",
    "\n",
    "    all_display_category_keys = set()\n",
    "    for summary in all_models_summary_stats:\n",
    "        if summary['status'] == 'Success':\n",
    "            all_display_category_keys.update(summary['category_accuracies'].keys())\n",
    "\n",
    "    sorted_display_category_keys = sorted(list(all_display_category_keys), key=sort_key_func)\n",
    "\n",
    "    header_parts = [\n",
    "        f\"{'模型 ID'.ljust(max_model_id_len)}\",\n",
    "        f\"{'状态'.ljust(12)}\",\n",
    "        f\"{'加载时间(s)'.rjust(10)}\",\n",
    "        f\"{'总体准确率'.rjust(12)}\"\n",
    "    ]\n",
    "    cat_col_width = 12\n",
    "    for cat_key in sorted_display_category_keys:\n",
    "        display_cat_key = cat_key.replace(\"-digit+-digit\", \"位+位\").replace(\"-digit\", \"位\")\n",
    "        header_parts.append(f\"{display_cat_key.rjust(cat_col_width)}\")\n",
    "\n",
    "    header = \" | \".join(header_parts)\n",
    "    log_message(header, print_to_console=True)\n",
    "    log_message(\"-\" * len(header), print_to_console=True)\n",
    "\n",
    "    if not all_models_summary_stats:\n",
    "        log_message(\"没有模型被测试或所有模型加载失败。\", print_to_console=True)\n",
    "    else:\n",
    "        for summary in all_models_summary_stats:\n",
    "            row_parts = [\n",
    "                summary['model_id'].ljust(max_model_id_len),\n",
    "                summary['status'].ljust(12),\n",
    "                summary.get('load_time_seconds', 'N/A').rjust(10),\n",
    "                summary.get('overall_accuracy', 'N/A').rjust(12)\n",
    "            ]\n",
    "            if summary['status'] != 'Load Failed':\n",
    "                for cat_key in sorted_display_category_keys:\n",
    "                    acc = summary.get('category_accuracies', {}).get(cat_key, 'N/A')\n",
    "                    row_parts.append(acc.rjust(cat_col_width))\n",
    "            else:\n",
    "                for _ in sorted_display_category_keys:\n",
    "                    row_parts.append('N/A'.rjust(cat_col_width))\n",
    "            log_message(\" | \".join(row_parts), print_to_console=True)\n",
    "\n",
    "    log_message(\"=\"*len(header), print_to_console=True)\n",
    "\n",
    "    log_message(\"\\n所有模型测试完成。\", print_to_console=True)\n",
    "    log_message(f\"测试结束时间: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", print_to_console=True)\n",
    "    log_message(f\"完整日志保存在: {os.path.abspath(log_file_name)}\", print_to_console=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
