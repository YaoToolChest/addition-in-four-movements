{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# --- 依赖检查 ---\n",
    "try:\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "    import torch\n",
    "except ImportError:\n",
    "    print(\"错误：未找到 'transformers' 或 'torch' 库。请先安装： pip install torch transformers accelerate\")\n",
    "    exit()\n",
    "\n",
    "# --- 配置 ---\n",
    "# 要测试的模型ID列表\n",
    "# 例如: [\"/data/global/model/llama3_instruct/\", \"/path/to/another_model\"]\n",
    "model_ids_to_test = [\n",
    "\"/root/autodl-tmp/llama\",\n",
    "\"/root/autodl-tmp/Mistral\",\n",
    "\"/root/autodl-tmp/Qwen2.5-Math-7B\",\n",
    "\"/root/autodl-tmp/AceMath\"\n",
    "]\n",
    "# 每个随机位数类别测试的数量\n",
    "num_random_tests = 4000 # 减少数量以便快速测试，您可以改回 500\n",
    "\n",
    "# 推理时使用的批量大小 (Batch Size for inference)\n",
    "BATCH_SIZE = 1000 # 根据您的 GPU 显存调整此值。如果遇到 OOM，请减小此值。\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# 日志文件配置\n",
    "log_directory = \"test1_logs\"\n",
    "os.makedirs(log_directory, exist_ok=True)\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file_name = os.path.join(log_directory, f\"llm_addition_test_log_{timestamp}.txt\")\n",
    "\n",
    "# --- 全局变量 ---\n",
    "current_log_file = None\n",
    "\n",
    "# --- 日志函数 ---\n",
    "def log_message(message, print_to_console=True):\n",
    "    \"\"\"将消息写入日志文件并可选择打印到控制台\"\"\"\n",
    "    global current_log_file\n",
    "    if current_log_file:\n",
    "        with open(current_log_file, 'a', encoding='utf-8') as f:\n",
    "            f.write(message + \"\\n\")\n",
    "    if print_to_console:\n",
    "        print(message)\n",
    "\n",
    "# --- 模型调用函数 (批量处理) ---\n",
    "def get_model_responses_batch(prompts: list, model, tokenizer, device):\n",
    "    if model is None or tokenizer is None:\n",
    "        return [\"[模型未加载]\" for _ in prompts]\n",
    "\n",
    "    try:\n",
    "        inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, return_attention_mask=True)\n",
    "        input_ids = inputs.input_ids.to(model.device if hasattr(model, 'device') else device)\n",
    "        attention_mask = inputs.attention_mask.to(model.device if hasattr(model, 'device') else device)\n",
    "        \n",
    "        num_input_tokens = input_ids.shape[1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_new_tokens=40, \n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                do_sample=False\n",
    "            )\n",
    "        \n",
    "        responses_text = []\n",
    "        for i in range(outputs.shape[0]):\n",
    "            response_ids = outputs[i][num_input_tokens:]\n",
    "            response_text = tokenizer.decode(response_ids, skip_special_tokens=True).strip()\n",
    "            responses_text.append(response_text)\n",
    "        return responses_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"模型批量生成过程中出错: {e} (处理中批量大小: {len(prompts)})\", print_to_console=True)\n",
    "        return [\"[生成错误]\" for _ in prompts]\n",
    "\n",
    "# --- 响应解析函数 ---\n",
    "def parse_response(response_text):\n",
    "    match = re.search(r'(-?\\d+)', response_text)\n",
    "    if match:\n",
    "        try:\n",
    "            return int(match.group(1))\n",
    "        except ValueError:\n",
    "            log_message(f\" [警告: 解析的数字过大或无效 '{match.group(1)}']\", print_to_console=False)\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# --- 辅助函数：获取数字位数类别 ---\n",
    "def get_digit_category(n1, n2):\n",
    "    len1 = len(str(abs(n1)))\n",
    "    len2 = len(str(abs(n2)))\n",
    "    max_digits = max(len1, len2)\n",
    "    if n1 == 0 and n2 == 0:\n",
    "        max_digits = 1\n",
    "    elif max_digits == 0 : # Catches cases like (0, 5) or (5, 0)\n",
    "        max_digits = 1\n",
    "    return f\"{max_digits}-digit\"\n",
    "\n",
    "# --- 批量测试运行函数 ---\n",
    "def run_batch_test(test_cases_xy: list, category_name: str, stats_dict: defaultdict, batch_size: int, model, tokenizer, device):\n",
    "    if not test_cases_xy:\n",
    "        return\n",
    "\n",
    "    stats_dict[category_name]['total'] += len(test_cases_xy)\n",
    "\n",
    "    num_processed_in_category = 0\n",
    "    for i in range(0, len(test_cases_xy), batch_size):\n",
    "        current_batch_xy = test_cases_xy[i : i + batch_size]\n",
    "        \n",
    "        if not current_batch_xy:\n",
    "            continue\n",
    "\n",
    "        prompts_chunk = []\n",
    "        correct_answers_chunk = []\n",
    "        \n",
    "        for x, y in current_batch_xy:\n",
    "            prompts_chunk.append(f\"Calculate: {x}+{y} = \")\n",
    "            correct_answers_chunk.append(x + y)\n",
    "        \n",
    "        raw_responses_chunk = get_model_responses_batch(prompts_chunk, model, tokenizer, device)\n",
    "\n",
    "        for j in range(len(raw_responses_chunk)):\n",
    "            # x_orig, y_orig = current_batch_xy[j] # Not strictly needed here if not logging x,y\n",
    "            prompt_text = prompts_chunk[j]\n",
    "            correct_answer = correct_answers_chunk[j]\n",
    "            raw_response = raw_responses_chunk[j]\n",
    "            num_processed_in_category +=1\n",
    "\n",
    "            log_line_prefix = f\"测试 ({category_name} {num_processed_in_category}/{len(test_cases_xy)}): {prompt_text}\"\n",
    "            model_answer = parse_response(raw_response)\n",
    "            \n",
    "            result_log = f\"模型原始输出: '{raw_response}' -> \"\n",
    "\n",
    "            if model_answer is not None:\n",
    "                if model_answer == correct_answer:\n",
    "                    result_log += f\"结果: {model_answer} (正确)\"\n",
    "                    stats_dict[category_name]['correct'] += 1\n",
    "                else:\n",
    "                    result_log += f\"结果: {model_answer} (错误! 正确答案是 {correct_answer})\"\n",
    "            else:\n",
    "                if raw_response == \"[模型未加载]\":\n",
    "                    result_log += \"结果: 模型未加载\"\n",
    "                elif raw_response == \"[生成错误]\":\n",
    "                    result_log += \"结果: 模型生成错误\"\n",
    "                elif not raw_response:\n",
    "                    result_log += \"结果: 模型无输出\"\n",
    "                else:\n",
    "                    result_log += f\"结果: 无法解析模型输出 ('{raw_response}')\"\n",
    "            log_message(f\"{log_line_prefix}{result_log}\", print_to_console=True)\n",
    "\n",
    "\n",
    "# Function to generate and run tests for a digit category\n",
    "def generate_and_run_digit_tests(num_digits, num_tests, stats, batch_size_param, model, tokenizer, device):\n",
    "    log_message(f\"\\n--- {num_digits}-位数测试 ({num_tests}次) ---\", print_to_console=True)\n",
    "    category = f\"{num_digits}-digit\"\n",
    "    test_cases = []\n",
    "    lower_bound = 0 if num_digits == 1 else 10**(num_digits - 1)\n",
    "    upper_bound = (10**num_digits) - 1\n",
    "    for _ in range(num_tests):\n",
    "        x = random.randint(lower_bound, upper_bound)\n",
    "        y = random.randint(lower_bound, upper_bound)\n",
    "        test_cases.append((x,y))\n",
    "    run_batch_test(test_cases, category, stats, batch_size_param, model, tokenizer, device)\n",
    "\n",
    "# --- 主测试循环 ---\n",
    "def main():\n",
    "    global current_log_file\n",
    "    current_log_file = log_file_name\n",
    "    log_message(f\"测试日志将保存在: {log_file_name}\", print_to_console=True)\n",
    "    log_message(f\"测试开始时间: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", print_to_console=True)\n",
    "\n",
    "    all_models_summary_stats = [] \n",
    "\n",
    "    for model_idx, current_model_id in enumerate(model_ids_to_test):\n",
    "        log_message(\"\\n\" + \"=\"*50, print_to_console=True)\n",
    "        log_message(f\"开始测试模型 {model_idx+1}/{len(model_ids_to_test)}: {current_model_id}\", print_to_console=True)\n",
    "        log_message(\"=\"*50, print_to_console=True)\n",
    "\n",
    "        model = None\n",
    "        tokenizer = None\n",
    "        log_message(f\"尝试使用设备: {device} (device_map='auto' 将主导模型放置)\", print_to_console=True)\n",
    "\n",
    "        model_load_start_time = time.time()\n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(current_model_id)\n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                current_model_id,\n",
    "                torch_dtype=torch.bfloat16,\n",
    "                device_map=device  \n",
    "            )\n",
    "            if tokenizer.pad_token is None:\n",
    "                tokenizer.pad_token = tokenizer.eos_token\n",
    "            \n",
    "            model_load_time = time.time() - model_load_start_time\n",
    "            log_message(f\"成功加载模型和分词器: {current_model_id} (耗时: {model_load_time:.2f} 秒)\", print_to_console=True)\n",
    "            \n",
    "            current_model_summary = {\n",
    "                'model_id': current_model_id,\n",
    "                'status': 'Success',\n",
    "                'load_time_seconds': f\"{model_load_time:.2f}\",\n",
    "                'overall_accuracy': 'N/A',\n",
    "                'category_accuracies': {}\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            model_load_time = time.time() - model_load_start_time\n",
    "            log_message(f\"错误：无法加载模型 '{current_model_id}'. 错误: {e} (尝试加载耗时: {model_load_time:.2f} 秒)\", print_to_console=True)\n",
    "            log_message(\"跳过此模型的测试。\", print_to_console=True)\n",
    "            all_models_summary_stats.append({\n",
    "                'model_id': current_model_id,\n",
    "                'status': 'Load Failed',\n",
    "                'load_time_seconds': f\"{model_load_time:.2f}\",\n",
    "                'overall_accuracy': 'N/A',\n",
    "                'category_accuracies': {}\n",
    "            })\n",
    "            if model is not None: del model\n",
    "            if tokenizer is not None: del tokenizer\n",
    "            if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "            continue\n",
    "\n",
    "        stats_by_digits = defaultdict(lambda: {'total': 0, 'correct': 0})\n",
    "        log_message(f\"\\n开始大语言模型 ({current_model_id}) 加法能力测试 (每类随机测试 {num_random_tests} 次, 批量大小: {BATCH_SIZE})...\", print_to_console=True)\n",
    "        \n",
    "        # --- 基本测试 ---\n",
    "        log_message(\"\\n--- 基本测试 ---\", print_to_console=True)\n",
    "        tests_basic_tuples = [(0, 0), (0, 1), (5, 8), (10, 25), (123, 0)]\n",
    "        categorized_basic_tests = defaultdict(list)\n",
    "        for x, y in tests_basic_tuples:\n",
    "            category = get_digit_category(x, y)\n",
    "            categorized_basic_tests[category].append((x,y))\n",
    "\n",
    "        for category, cases in categorized_basic_tests.items():\n",
    "            log_message(f\"处理基本测试类别: {category} ({len(cases)} 个案例)\", print_to_console=True)\n",
    "            run_batch_test(cases, category, stats_by_digits, BATCH_SIZE, model, tokenizer, device)\n",
    "\n",
    "        # --- N-位数测试 (1到6位) ---\n",
    "        for num_digits_test in range(1, 7): \n",
    "             generate_and_run_digit_tests(num_digits_test, num_random_tests, stats_by_digits, BATCH_SIZE, model, tokenizer, device)\n",
    "\n",
    "        # --- 进位复杂情况测试 ---\n",
    "        log_message(\"\\n--- 进位复杂情况测试 ---\", print_to_console=True)\n",
    "        tests_carry_tuples = [\n",
    "            (9, 9), (8, 7), (99, 99), (88, 77), (999, 999), (1, 999),\n",
    "            (9999, 9999), (1234, 8765), (99999, 99999), (1, 99999),\n",
    "            (999999, 999999), (123456, 876543)\n",
    "        ]\n",
    "        categorized_carry_tests = defaultdict(list)\n",
    "        for x, y in tests_carry_tuples:\n",
    "            category = get_digit_category(x, y)\n",
    "            categorized_carry_tests[category].append((x,y))\n",
    "\n",
    "        # Sort carry tests by digit category for consistent logging\n",
    "        sorted_carry_test_items = sorted(categorized_carry_tests.items(), \n",
    "                                         key=lambda item: int(re.search(r'(\\d+)', item[0]).group(1)) if re.search(r'(\\d+)', item[0]) else 0)\n",
    "        for category, cases in sorted_carry_test_items:\n",
    "            log_message(f\"处理进位测试类别: {category} ({len(cases)} 个案例)\", print_to_console=True)\n",
    "            run_batch_test(cases, category, stats_by_digits, BATCH_SIZE, model, tokenizer, device)\n",
    "\n",
    "        # --- 当前模型的最终统计 ---\n",
    "        log_message(\"\\n\" + \"=\"*40, print_to_console=True)\n",
    "        log_message(f\" 测试统计结果: {current_model_id}\", print_to_console=True)\n",
    "        log_message(\" (按最大操作数位数分类)\", print_to_console=True)\n",
    "        log_message(\"=\"*40, print_to_console=True)\n",
    "\n",
    "        total_overall = 0\n",
    "        correct_overall = 0\n",
    "        \n",
    "        category_accuracies_for_current_model = {}\n",
    "        # Sort categories numerically for display and storage\n",
    "        sorted_category_keys_for_model = sorted(stats_by_digits.keys(), \n",
    "                                               key=lambda k: int(re.search(r'(\\d+)', k).group(1)) if re.search(r'(\\d+)', k) else float('inf'))\n",
    "\n",
    "        for category in sorted_category_keys_for_model:\n",
    "            stats = stats_by_digits[category]\n",
    "            total = stats['total']\n",
    "            correct = stats['correct']\n",
    "            total_overall += total\n",
    "            correct_overall += correct\n",
    "            accuracy_str = \"N/A\"\n",
    "            if total > 0:\n",
    "                accuracy = (correct / total) * 100\n",
    "                accuracy_str = f\"{accuracy:.2f}%\"\n",
    "                log_message(f\"类别: {category.rjust(8)} | 总数: {str(total).rjust(4)} | 正确: {str(correct).rjust(4)} | 准确率: {accuracy_str.rjust(7)}\", print_to_console=True)\n",
    "            else:\n",
    "                # Only log if it was an expected category to avoid clutter\n",
    "                if category in categorized_basic_tests or \\\n",
    "                   category in categorized_carry_tests or \\\n",
    "                   any(f\"{d}-digit\" == category for d in range(1,7)):\n",
    "                    log_message(f\"类别: {category.rjust(8)} | 总数: {str(total).rjust(4)} | 正确: {str(correct).rjust(4)} | 准确率: {accuracy_str.rjust(7)}\", print_to_console=True)\n",
    "            category_accuracies_for_current_model[category] = accuracy_str\n",
    "        \n",
    "        current_model_summary['category_accuracies'] = category_accuracies_for_current_model\n",
    "\n",
    "        log_message(\"-\"*40, print_to_console=True)\n",
    "        if total_overall > 0:\n",
    "            overall_accuracy_val = (correct_overall / total_overall) * 100\n",
    "            overall_accuracy_str = f\"{overall_accuracy_val:.2f}%\"\n",
    "            log_message(f\"总体 {' '.rjust(8)} | 总数: {str(total_overall).rjust(4)} | 正确: {str(correct_overall).rjust(4)} | 准确率: {overall_accuracy_str.rjust(7)}\", print_to_console=True)\n",
    "            current_model_summary['overall_accuracy'] = overall_accuracy_str\n",
    "        else:\n",
    "            log_message(f\"总体 {' '.rjust(8)} | 总数: {str(0).rjust(4)} | 正确: {str(0).rjust(4)} | 准确率: {'N/A'.rjust(7)}\", print_to_console=True)\n",
    "            current_model_summary['overall_accuracy'] = 'N/A'\n",
    "        \n",
    "        all_models_summary_stats.append(current_model_summary)\n",
    "        log_message(\"=\"*40, print_to_console=True)\n",
    "\n",
    "        log_message(f\"完成模型 {current_model_id} 的测试。卸载模型...\", print_to_console=True)\n",
    "        del model\n",
    "        del tokenizer\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        log_message(f\"模型 {current_model_id} 已卸载。\", print_to_console=True)\n",
    "\n",
    "    # --- 所有模型测试完成后的最终摘要表 ---\n",
    "    log_message(\"\\n\\n\" + \"=\"*120, print_to_console=True) # Increased width for more columns\n",
    "    log_message(\" \" * 45 + \"总体模型性能摘要\" + \" \" * 45, print_to_console=True)\n",
    "    log_message(\"=\"*120, print_to_console=True)\n",
    "    \n",
    "    max_model_id_len = max(len(s['model_id']) for s in all_models_summary_stats) if all_models_summary_stats else 20\n",
    "    max_model_id_len = max(max_model_id_len, len(\"模型 ID\")) \n",
    "\n",
    "    # Collect all unique category keys from all successful tests for table headers\n",
    "    all_display_category_keys = set()\n",
    "    for summary in all_models_summary_stats:\n",
    "        if summary['status'] == 'Success':\n",
    "            all_display_category_keys.update(summary['category_accuracies'].keys())\n",
    "    \n",
    "    # Sort categories: 1-digit, 2-digit, ..., then others alphabetically if any\n",
    "    sorted_display_category_keys = sorted(\n",
    "        list(all_display_category_keys),\n",
    "        key=lambda k: (0, int(re.search(r'(\\d+)', k).group(1))) if re.search(r'(\\d+)-digit', k) else (1, k)\n",
    "    )\n",
    "\n",
    "    header_parts = [\n",
    "        f\"{'模型 ID'.ljust(max_model_id_len)}\",\n",
    "        f\"{'状态'.ljust(12)}\", # Adjusted width\n",
    "        f\"{'加载时间(s)'.rjust(10)}\",\n",
    "        f\"{'总体准确率'.rjust(12)}\"\n",
    "    ]\n",
    "    cat_col_width = 9 # Width for each category accuracy column e.g. \"100.00%\"\n",
    "    for cat_key in sorted_display_category_keys:\n",
    "        # Shorten category key for header if it's standard N-digit\n",
    "        display_cat_key = cat_key.replace(\"-digit\", \"位\") if \"-digit\" in cat_key else cat_key\n",
    "        header_parts.append(f\"{display_cat_key.rjust(cat_col_width)}\")\n",
    "    \n",
    "    header = \" | \".join(header_parts)\n",
    "    log_message(header, print_to_console=True)\n",
    "    log_message(\"-\" * len(header), print_to_console=True)\n",
    "\n",
    "    if not all_models_summary_stats:\n",
    "        log_message(\"没有模型被测试或所有模型加载失败。\", print_to_console=True)\n",
    "    else:\n",
    "        for summary in all_models_summary_stats:\n",
    "            row_parts = [\n",
    "                summary['model_id'].ljust(max_model_id_len),\n",
    "                summary['status'].ljust(12),\n",
    "                summary.get('load_time_seconds', 'N/A').rjust(10),\n",
    "                summary.get('overall_accuracy', 'N/A').rjust(12)\n",
    "            ]\n",
    "            if summary['status'] != 'Load Failed':\n",
    "                for cat_key in sorted_display_category_keys:\n",
    "                    acc = summary.get('category_accuracies', {}).get(cat_key, 'N/A')\n",
    "                    row_parts.append(acc.rjust(cat_col_width))\n",
    "            else: # For failed models, fill category columns with N/A\n",
    "                for _ in sorted_display_category_keys:\n",
    "                    row_parts.append('N/A'.rjust(cat_col_width))\n",
    "            \n",
    "            log_message(\" | \".join(row_parts), print_to_console=True)\n",
    "    \n",
    "    log_message(\"=\"*len(header), print_to_console=True)\n",
    "\n",
    "    log_message(\"\\n所有模型测试完成。\", print_to_console=True)\n",
    "    log_message(f\"测试结束时间: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", print_to_console=True)\n",
    "    log_message(f\"完整日志保存在: {os.path.abspath(log_file_name)}\", print_to_console=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMAL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
